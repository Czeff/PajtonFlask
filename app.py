from flask import Flask, request, jsonify, render_template_string, send_file
from werkzeug.utils import secure_filename
from PIL import Image, ImageFilter, ImageOps, ImageEnhance, ImageDraw, ImageFont
import os
import time
import math
import json
import io
import traceback
import gc
from collections import defaultdict
import numpy as np
from scipy import ndimage
from skimage import measure, morphology, segmentation
from skimage.filters import gaussian
from skimage.color import rgb2lab, lab2rgb
try:
    import cv2
except ImportError:
    print("锔 OpenCV nie jest dostpne - u偶ywam fallback metod")
    cv2 = None

app = Flask(__name__)

# Konfiguracja
UPLOAD_FOLDER = 'uploads'
MAX_FILE_SIZE = 8 * 1024 * 1024  # 8MB
MAX_IMAGE_SIZE = 1200  # Znacznie zwikszono dla maksymalnej jakoci detali
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'webp', 'svg'}

# Upewnij si, 偶e katalogi istniej
for folder in ['raster', 'vector_auto', 'vector_manual', 'preview']:
    os.makedirs(os.path.join(UPLOAD_FOLDER, folder), exist_ok=True)

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def optimize_image_for_vectorization(image_path, max_size=MAX_IMAGE_SIZE):
    """Ultra zaawansowana optymalizacja obrazu z zachowaniem szczeg贸贸w oryginalnego"""
    try:
        with Image.open(image_path) as img:
            # Konwersja do RGB z zachowaniem jakoci
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # OPTYMALIZACJA: Kontrolowana rozdzielczo dla lepszej jakoci
            original_width, original_height = img.size
            if max(original_width, original_height) < 400:
                # Mae obrazy - zwiksz 2x dla zachowania detali
                target_size = min(max_size * 2, 1200)
            elif max(original_width, original_height) < 800:
                # rednie obrazy - zwiksz 1.5x
                target_size = min(max_size * 1.5, 900)
            else:
                # Wiksze obrazy - zachowuj oryginalny rozmiar z kontrol
                target_size = max_size
            
            # Wysokiej jakoci skalowanie z zachowaniem ostroci
            if max(original_width, original_height) > target_size:
                img.thumbnail((target_size, target_size), Image.Resampling.LANCZOS)
            elif max(original_width, original_height) < target_size * 0.8:
                # Zwiksz mae obrazy dla lepszej jakoci detali
                scale_factor = target_size / max(original_width, original_height)
                new_width = int(original_width * scale_factor)
                new_height = int(original_height * scale_factor)
                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # Multi-pass enhancement dla cartoon-style images z zachowaniem detali
            img = enhance_cartoon_precision_ultra(img)
            
            return img
    except Exception as e:
        print(f"Bd podczas optymalizacji obrazu: {e}")
        return None

def enhance_cartoon_precision_ultra(img):
    """Ultra precyzja dla obraz贸w cartoon-style z zachowaniem najmniejszych detali"""
    try:
        # Bardzo delikatne zwikszenie kontrastu z zachowaniem detali
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.2)
        
        # Multi-step wyostrzenie krawdzi z zachowaniem detali
        img = img.filter(ImageFilter.UnsharpMask(radius=0.3, percent=120, threshold=1))
        img = img.filter(ImageFilter.UnsharpMask(radius=0.8, percent=80, threshold=2))
        
        # Bardzo delikatna redukcja szumu bez utraty detali
        img = img.filter(ImageFilter.SMOOTH)
        
        # Zwikszenie nasycenia dla lepszego wykrywania kolor贸w
        enhancer = ImageEnhance.Color(img)
        img = enhancer.enhance(1.1)
        
        # Finalne delikatne wyostrzenie
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.2)
        
        return img
    except Exception as e:
        print(f"Bd w enhance_cartoon_precision_ultra: {e}")
        return img

def enhance_cartoon_precision(img):
    """Ulepszona precyzja dla obraz贸w cartoon-style"""
    try:
        # Delikatne zwikszenie kontrastu bez utraty szczeg贸贸w
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.3)
        
        # Precyzyjne wyostrzenie krawdzi
        img = img.filter(ImageFilter.UnsharpMask(radius=0.5, percent=150, threshold=2))
        
        # Redukcja szumu przy zachowaniu detali
        img = img.filter(ImageFilter.SMOOTH_MORE)
        
        # Finalne wyostrzenie
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.4)
        
        return img
    except Exception as e:
        print(f"Bd w enhance_cartoon_precision: {e}")
        return img

def detect_edge_density(img_array):
    """Wykrywa gsto krawdzi w obrazie"""
    try:
        from scipy import ndimage
        gray = np.mean(img_array, axis=2)
        edges = ndimage.sobel(gray)
        return np.mean(np.abs(edges)) / 255.0
    except:
        return 0.1

def detect_color_complexity(img_array):
    """Wykrywa zo偶ono kolorow obrazu"""
    try:
        # Zlicz unikalne kolory w zmniejszonym obrazie
        small = img_array[::4, ::4]
        colors = np.unique(small.reshape(-1, 3), axis=0)
        return len(colors)
    except:
        return 100

def enhance_vector_graphics(img):
    """Optymalizacja dla grafik wektorowych/logo"""
    # Zwiksz kontrast dramatycznie
    enhancer = ImageEnhance.Contrast(img)
    img = enhancer.enhance(2.0)
    
    # Maksymalna ostro
    enhancer = ImageEnhance.Sharpness(img)
    img = enhancer.enhance(2.5)
    
    # Zwiksz nasycenie
    enhancer = ImageEnhance.Color(img)
    img = enhancer.enhance(1.5)
    
    return img

def enhance_cartoon_style(img):
    """Optymalizacja dla cartoon-style"""
    # Umiarkowany kontrast
    enhancer = ImageEnhance.Contrast(img)
    img = enhancer.enhance(1.4)
    
    # Zwiksz ostro
    enhancer = ImageEnhance.Sharpness(img)
    img = enhancer.enhance(1.8)
    
    # Nasycenie kolor贸w
    enhancer = ImageEnhance.Color(img)
    img = enhancer.enhance(1.3)
    
    # Filtr wygadzajcy zachowujcy krawdzie
    img = img.filter(ImageFilter.EDGE_ENHANCE_MORE)
    
    return img

def enhance_photo_for_vector(img):
    """Przygotowanie zdj fotorealistycznych"""
    # Delikatny kontrast
    enhancer = ImageEnhance.Contrast(img)
    img = enhancer.enhance(1.2)
    
    # Redukcja szumu
    img = img.filter(ImageFilter.SMOOTH_MORE)
    
    # Delikatne zwikszenie ostroci
    enhancer = ImageEnhance.Sharpness(img)
    img = enhancer.enhance(1.1)
    
    return img

def flatten_color_palette(colors, target_count=16):
    """Spaszcza palet kolor贸w do okrelonej liczby zachowujc najwa偶niejsze odcienie"""
    if len(colors) <= target_count:
        return colors
    
    try:
        from sklearn.cluster import KMeans
        
        # Konwertuj kolory do przestrzeni LAB dla lepszej percepcji
        lab_colors = []
        for color in colors:
            try:
                from skimage.color import rgb2lab
                lab = rgb2lab(np.array(color).reshape(1, 1, 3) / 255.0)[0, 0]
                lab_colors.append(lab)
            except:
                # Fallback do RGB
                lab_colors.append(color)
        
        # K-means clustering w przestrzeni LAB
        if lab_colors:
            kmeans = KMeans(n_clusters=target_count, random_state=42, n_init=20, max_iter=300)
            kmeans.fit(lab_colors)
            
            # Konwertuj z powrotem do RGB
            flattened_colors = []
            for lab_center in kmeans.cluster_centers_:
                try:
                    from skimage.color import lab2rgb
                    if len(lab_center) == 3:  # LAB color
                        rgb = lab2rgb(lab_center.reshape(1, 1, 3))[0, 0]
                        rgb = np.clip(rgb * 255, 0, 255).astype(int)
                        flattened_colors.append(tuple(rgb))
                    else:  # Already RGB
                        flattened_colors.append(tuple(np.clip(lab_center, 0, 255).astype(int)))
                except:
                    # Fallback
                    flattened_colors.append(tuple(np.clip(lab_center[:3], 0, 255).astype(int)))
            
            print(f" Spaszczono {len(colors)} kolor贸w do {len(flattened_colors)} kolor贸w podstawowych")
            return flattened_colors
        
        return colors[:target_count]
    except:
        print(f"锔 Bd spaszczania - u偶ywam prostego obcinania do {target_count} kolor贸w")
        return colors[:target_count]

def enhance_image_quality_ultra_maximum(image):
    """ULTRA maksymalne podniesienie jakoci obrazu z perfekcyjnym zachowaniem ka偶dego detalu"""
    try:
        print(" Rozpoczynanie ULTRA maksymalnego podniesienia jakoci...")
        
        # Pass 1: Bardzo precyzyjne zwikszenie kontrastu z zachowaniem najdrobniejszych detali
        enhancer = ImageEnhance.Contrast(image)
        enhanced = enhancer.enhance(1.35)
        
        # Pass 2: Multi-stage ultra precyzyjne wyostrzenie krawdzi
        enhanced = enhanced.filter(ImageFilter.UnsharpMask(radius=0.2, percent=140, threshold=0))
        enhanced = enhanced.filter(ImageFilter.UnsharpMask(radius=0.5, percent=100, threshold=1))
        enhanced = enhanced.filter(ImageFilter.UnsharpMask(radius=1.0, percent=60, threshold=2))
        
        # Pass 3: Zwikszenie nasycenia kolor贸w dla perfekcyjnego wykrywania
        enhancer = ImageEnhance.Color(enhanced)
        enhanced = enhancer.enhance(1.25)
        
        # Pass 4: Bardzo delikatna redukcja szumu zachowujca wszystkie detale
        enhanced = enhanced.filter(ImageFilter.SMOOTH_MORE)
        
        # Pass 5: Progresywne wyostrzenie w kilku etapach
        enhancer = ImageEnhance.Sharpness(enhanced)
        enhanced = enhancer.enhance(1.4)
        enhanced = enhanced.filter(ImageFilter.EDGE_ENHANCE_MORE)
        
        # Pass 6: Finalne zwikszenie jasnoci dla maksymalnego kontrastu
        enhancer = ImageEnhance.Brightness(enhanced)
        enhanced = enhancer.enhance(1.08)
        
        # Pass 7: Ultra precyzyjne wyostrzenie najmniejszych detali
        enhanced = enhanced.filter(ImageFilter.UnsharpMask(radius=0.1, percent=80, threshold=0))
        
        # Pass 8: Kocowe dopracowanie krawdzi
        enhanced = enhanced.filter(ImageFilter.FIND_EDGES)
        enhanced = ImageEnhance.Contrast(enhanced).enhance(0.3)  # Delikatne dodanie krawdzi
        original_enhanced = ImageEnhance.Contrast(image).enhance(1.35)
        from PIL import ImageChops
        enhanced = ImageChops.add(original_enhanced, enhanced)
        
        print(" ULTRA maksymalne podniesienie jakoci zakoczone")
        return enhanced
    except Exception as e:
        print(f"Bd w enhance_image_quality_ultra_maximum: {e}")
        return enhance_image_quality_maximum(image)

def enhance_image_quality_maximum(image):
    """Maksymalne podniesienie jakoci obrazu dla cartoon-style z jeszcze wy偶sz precyzj"""
    try:
        # Ultra multi-pass enhancement z maksymalnym zachowaniem szczeg贸贸w
        
        # Pass 1: Precyzyjne zwikszenie kontrastu z zachowaniem detali
        enhancer = ImageEnhance.Contrast(image)
        enhanced = enhancer.enhance(1.25)
        
        # Pass 2: Zaawansowane wyostrzenie krawdzi wielopoziomowe
        enhanced = enhanced.filter(ImageFilter.UnsharpMask(radius=0.3, percent=120, threshold=1))
        enhanced = enhanced.filter(ImageFilter.UnsharpMask(radius=0.8, percent=80, threshold=2))
        
        # Pass 3: Zwikszenie nasycenia dla lepszego wykrywania kolor贸w
        enhancer = ImageEnhance.Color(enhanced)
        enhanced = enhancer.enhance(1.15)
        
        # Pass 4: Selektywna redukcja szumu z zachowaniem krawdzi
        enhanced = enhanced.filter(ImageFilter.SMOOTH)
        
        # Pass 5: Multi-level wyostrzenie
        enhancer = ImageEnhance.Sharpness(enhanced)
        enhanced = enhancer.enhance(1.3)
        
        # Pass 6: Finalne zwikszenie jasnoci dla lepszego kontrastu
        enhancer = ImageEnhance.Brightness(enhanced)
        enhanced = enhancer.enhance(1.05)
        
        # Pass 7: Kocowe precyzyjne wyostrzenie detali
        enhanced = enhanced.filter(ImageFilter.UnsharpMask(radius=0.1, percent=50, threshold=0))
        
        return enhanced
    except Exception as e:
        print(f"Bd w enhance_image_quality_maximum: {e}")
        return image

def extract_dominant_colors_advanced(image, max_colors=50, params=None):
    """Ultra precyzyjna analiza kolor贸w z perfekcyjnym dopasowaniem cartoon-style"""
    try:
        img_array = np.array(image)
        
        # Pobierz parametry jakoci
        quality_level = params.get('quality_enhancement', 'high') if params else 'high'
        tolerance_factor = params.get('tolerance_factor', 0.8) if params else 0.8
        
        print(f" Analiza kolor贸w: jako={quality_level}, tolerancja={tolerance_factor}, max_kolor贸w={max_colors}")
        
        # Wielopoziomowa analiza kolor贸w z adaptacyjnymi parametrami
        colors = []
        
        # 1. Precyzyjne wykrywanie kolor贸w dominujcych - zwikszona precyzja
        dominant_portion = max_colors // 2 if quality_level == 'maximum' else max_colors // 3
        dominant_colors = extract_precise_dominant_colors(img_array, dominant_portion)
        colors.extend(dominant_colors)
        
        # 2. Analiza kolor贸w krawdzi (kluczowe dla cartoon-style) - zwikszona dla wysokiej jakoci
        edge_portion = max_colors // 3 if quality_level == 'maximum' else max_colors // 4
        edge_colors = extract_edge_based_colors(img_array, edge_portion)
        colors.extend(edge_colors)
        
        # 3. Analiza kolor贸w przej i gradient贸w - tylko dla wysokiej jakoci
        if quality_level in ['maximum', 'high']:
            gradient_colors = extract_gradient_colors(img_array, max_colors // 6)
            colors.extend(gradient_colors)
        
        # 4. Wykrywanie kolor贸w maych obszar贸w - zwikszona precyzja
        if quality_level == 'maximum':
            detail_colors = extract_detail_colors(img_array, max_colors // 5)
            colors.extend(detail_colors)
        
        # 5. Wykrywanie kolor贸w cieni i rozjanie
        shadow_highlight_colors = extract_shadow_highlight_colors(img_array, max_colors // 8)
        colors.extend(shadow_highlight_colors)
        
        # 6. K-means clustering z najwy偶sz precyzj
        if len(colors) < max_colors:
            additional_colors = extract_high_precision_kmeans(img_array, max_colors - len(colors))
            colors.extend(additional_colors)
        
        # Usuwanie duplikat贸w z dostosowan tolerancj
        final_colors = remove_similar_colors_ultra_precise(colors, max_colors, tolerance_factor)
        
        # Sortowanie wedug wa偶noci wizualnej w obrazie
        final_colors = sort_colors_by_visual_importance(img_array, final_colors)
        
        print(f" Perfekcyjna analiza: {len(final_colors)} kolor贸w z maksymaln precyzj (jako: {quality_level})")
        return final_colors
        
    except Exception as e:
        print(f"Bd podczas perfekcyjnej analizy kolor贸w: {e}")
        return extract_dominant_colors_simple(image, max_colors)

def extract_precise_dominant_colors(img_array, max_colors):
    """Precyzyjne wyciganie kolor贸w dominujcych"""
    try:
        from sklearn.cluster import KMeans
        
        # Pr贸bkowanie z zachowaniem reprezentatywnoci
        height, width = img_array.shape[:2]
        sample_rate = min(0.3, 50000 / (height * width))
        
        pixels = img_array.reshape(-1, 3)
        if len(pixels) > 50000:
            step = int(1 / sample_rate)
            pixels = pixels[::step]
        
        # K-means z wiksz liczb iteracji dla precyzji
        kmeans = KMeans(n_clusters=max_colors, random_state=42, n_init=30, max_iter=500)
        kmeans.fit(pixels)
        
        return [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]
    except:
        return []

def extract_edge_based_colors(img_array, max_colors):
    """Wyciga kolory z obszar贸w krawdzi - kluczowe dla cartoon-style"""
    try:
        from scipy import ndimage
        
        # Wykryj krawdzie z wysok precyzj
        gray = np.mean(img_array, axis=2)
        edges = ndimage.sobel(gray)
        
        # Threshold adaptacyjny
        threshold = np.percentile(edges, 85)
        edge_mask = edges > threshold
        
        # Rozszerz obszary krawdzi
        from scipy.ndimage import binary_dilation
        edge_mask = binary_dilation(edge_mask, iterations=2)
        
        # Wycignij kolory z obszar贸w krawdzi
        edge_pixels = img_array[edge_mask]
        
        if len(edge_pixels) > 1000:
            from sklearn.cluster import KMeans
            n_clusters = min(max_colors, len(edge_pixels) // 100)
            if n_clusters > 0:
                kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                kmeans.fit(edge_pixels)
                return [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]
        
        return []
    except:
        return []

def extract_gradient_colors(img_array, max_colors):
    """Wyciga kolory z obszar贸w gradient贸w"""
    try:
        from scipy import ndimage
        
        # Oblicz gradienty dla ka偶dego kanau
        gradients = []
        for channel in range(3):
            grad_x = ndimage.sobel(img_array[:,:,channel], axis=1)
            grad_y = ndimage.sobel(img_array[:,:,channel], axis=0)
            gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
            gradients.append(gradient_magnitude)
        
        # Znajd藕 obszary z wysokimi gradientami
        total_gradient = np.sum(gradients, axis=0)
        threshold = np.percentile(total_gradient, 70)
        gradient_mask = total_gradient > threshold
        
        # Wycignij kolory z tych obszar贸w
        gradient_pixels = img_array[gradient_mask]
        
        if len(gradient_pixels) > 500:
            # Clustering kolor贸w gradient贸w
            from sklearn.cluster import KMeans
            n_clusters = min(max_colors, len(gradient_pixels) // 200)
            if n_clusters > 0:
                kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                kmeans.fit(gradient_pixels)
                return [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]
        
        return []
    except:
        return []

def extract_detail_colors(img_array, max_colors):
    """Wyciga kolory z maych szczeg贸贸w i tekstur"""
    try:
        from sklearn.cluster import KMeans
        from scipy import ndimage
        
        # Wykryj mae obiekty i detale
        gray = np.mean(img_array, axis=2)
        
        # Filtr Laplace'a do wykrywania szczeg贸贸w
        laplacian = ndimage.laplace(gray)
        detail_mask = np.abs(laplacian) > np.percentile(np.abs(laplacian), 85)
        
        # Rozszerz obszary szczeg贸贸w
        detail_mask = ndimage.binary_dilation(detail_mask, iterations=1)
        
        # Wycignij kolory z obszar贸w szczeg贸贸w
        detail_pixels = img_array[detail_mask]
        
        if len(detail_pixels) > 100:
            # U偶ywaj wikszej liczby klastr贸w dla szczeg贸贸w
            n_clusters = min(max_colors, max(5, len(detail_pixels) // 50))
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20)
            kmeans.fit(detail_pixels)
            return [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]
        
        return []
    except:
        return []

def extract_texture_colors(img_array, max_colors):
    """Wyciga kolory z obszar贸w z tekstur"""
    try:
        from sklearn.cluster import KMeans
        from scipy import ndimage
        
        # Zastosuj filtry teksturowe
        gray = np.mean(img_array, axis=2)
        
        # Filtr Gabora (uproszczony) - wykrywa tekstury
        gx = ndimage.sobel(gray, axis=0)
        gy = ndimage.sobel(gray, axis=1)
        texture_response = np.sqrt(gx**2 + gy**2)
        
        # Znajd藕 obszary z wysok odpowiedzi teksturow
        texture_threshold = np.percentile(texture_response, 75)
        texture_mask = texture_response > texture_threshold
        
        # Wycignij kolory z obszar贸w teksturowych
        texture_pixels = img_array[texture_mask]
        
        if len(texture_pixels) > 200:
            n_clusters = min(max_colors, len(texture_pixels) // 100)
            if n_clusters > 0:
                kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                kmeans.fit(texture_pixels)
                return [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]
        
        return []
    except:
        return []

def extract_shadow_highlight_colors(img_array, max_colors):
    """Wyciga kolory cieni i rozjanie - kluczowe dla cartoon-style"""
    try:
        from sklearn.cluster import KMeans
        
        # Oblicz jasno ka偶dego piksela
        brightness = np.mean(img_array, axis=2)
        
        # Znajd藕 bardzo ciemne obszary (cienie)
        shadow_threshold = np.percentile(brightness, 15)
        shadow_mask = brightness <= shadow_threshold
        
        # Znajd藕 bardzo jasne obszary (rozjanienia)
        highlight_threshold = np.percentile(brightness, 85)
        highlight_mask = brightness >= highlight_threshold
        
        colors = []
        
        # Wycignij kolory cieni
        shadow_pixels = img_array[shadow_mask]
        if len(shadow_pixels) > 100:
            n_clusters = min(max_colors // 2, len(shadow_pixels) // 200)
            if n_clusters > 0:
                kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                kmeans.fit(shadow_pixels)
                shadow_colors = [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]
                colors.extend(shadow_colors)
        
        # Wycignij kolory rozjanie
        highlight_pixels = img_array[highlight_mask]
        if len(highlight_pixels) > 100:
            n_clusters = min(max_colors // 2, len(highlight_pixels) // 200)
            if n_clusters > 0:
                kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                kmeans.fit(highlight_pixels)
                highlight_colors = [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]
                colors.extend(highlight_colors)
        
        return colors[:max_colors]
    except:
        return []

def remove_similar_colors_ultra_precise(colors, max_colors, tolerance_factor=0.8):
    """Ultra precyzyjne usuwanie podobnych kolor贸w z maksymalnie liberalnym podejciem"""
    if not colors:
        return []
    
    final_colors = [colors[0]]
    
    for color in colors[1:]:
        is_unique = True
        
        for existing in final_colors:
            # Zaawansowane obliczanie r贸偶nicy kolor贸w w przestrzeni LAB
            distance = calculate_advanced_color_distance(color, existing)
            
            # DRASTYCZNIE zmniejszone progi - zachowaj praktycznie wszystkie odcienie
            brightness = sum(existing) / 3
            saturation = max(existing) - min(existing)
            
            # Minimalne progi tolerancji dla maksymalnej szczeg贸owoci
            if brightness < 30:  # Bardzo ciemne kolory
                base_tolerance = 0.8
            elif brightness < 60:  # Ciemne kolory
                base_tolerance = 1.0
            elif brightness < 120:  # rednio ciemne
                base_tolerance = 1.2
            elif brightness > 230:  # Bardzo jasne kolory
                base_tolerance = 2.0
            elif brightness > 200:  # Jasne kolory
                base_tolerance = 1.8
            elif brightness > 160:  # rednio jasne
                base_tolerance = 1.5
            else:  # rednie kolory
                base_tolerance = 1.3
            
            # Zastosuj bardzo liberalny czynnik tolerancji
            tolerance = base_tolerance * tolerance_factor
            
            # Dodatkowa tolerancja dla wysoko nasyconych kolor贸w (typowe w cartoon)
            if saturation > 120:  # Bardzo nasycone
                tolerance += 5
            elif saturation > 80:  # Nasycone
                tolerance += 3
            elif saturation < 20:  # Szare/niskie nasycenie
                tolerance -= 2
            
            # Specjalna logika dla kolor贸w sk贸ry (cartoon-style czsto ma specyficzne odcienie)
            if is_skin_tone(existing) and is_skin_tone(color):
                tolerance = max(4, tolerance * 0.6)  # Mniejsza tolerancja dla odcieni sk贸ry
            
            # Specjalna logika dla zieleni (licie, trawa w cartoon)
            if is_green_tone(existing) and is_green_tone(color):
                tolerance *= 0.8  # Mniejsza tolerancja dla odcieni zieleni
                
            # Dodatkowa precyzja dla podstawowych kolor贸w cartoon
            if is_primary_cartoon_color(existing) or is_primary_cartoon_color(color):
                tolerance *= 0.7
            
            if distance < tolerance:
                is_unique = False
                break
        
        if is_unique and len(final_colors) < max_colors:
            final_colors.append(color)
    
    return final_colors

def is_skin_tone(color):
    """Sprawdza czy kolor to odcie sk贸ry"""
    r, g, b = color[:3]
    # Typowe zakresy dla odcieni sk贸ry
    return (120 <= r <= 255 and 80 <= g <= 220 and 60 <= b <= 180 and 
            r > g > b and r - g < 80 and g - b < 60)

def is_green_tone(color):
    """Sprawdza czy kolor to odcie zieleni"""
    r, g, b = color[:3]
    # Zielone odcienie - g dominuje
    return g > r and g > b and g > 80

def is_primary_cartoon_color(color):
    """Sprawdza czy to podstawowy kolor cartoon (czerwony, niebieski, 偶贸ty, etc.)"""
    r, g, b = color[:3]
    
    # Czerwony
    if r > 180 and g < 80 and b < 80:
        return True
    # Niebieski
    if b > 180 and r < 80 and g < 80:
        return True
    # 呕贸ty
    if r > 180 and g > 180 and b < 80:
        return True
    # Czarny
    if r < 50 and g < 50 and b < 50:
        return True
    # Biay
    if r > 220 and g > 220 and b > 220:
        return True
    
    return False

def calculate_advanced_color_distance(color1, color2):
    """Zaawansowane obliczanie odlegoci kolor贸w z Delta E 2000"""
    try:
        from skimage.color import rgb2lab, deltaE_cie76
        
        # Konwersja do przestrzeni LAB
        c1_lab = rgb2lab(np.array(color1).reshape(1, 1, 3) / 255.0)[0, 0]
        c2_lab = rgb2lab(np.array(color2).reshape(1, 1, 3) / 255.0)[0, 0]
        
        # Delta E CIE76 - bardziej precyzyjna miara r贸偶nicy kolor贸w
        delta_e = np.sqrt(
            (c1_lab[0] - c2_lab[0])**2 + 
            (c1_lab[1] - c2_lab[1])**2 + 
            (c1_lab[2] - c2_lab[2])**2
        )
        return delta_e
    except:
        # Fallback do ulepszonej Euclidean distance z wagami
        r_diff = (color1[0] - color2[0]) * 0.299
        g_diff = (color1[1] - color2[1]) * 0.587
        b_diff = (color1[2] - color2[2]) * 0.114
        return np.sqrt(r_diff**2 + g_diff**2 + b_diff**2)

def sort_colors_by_visual_importance(img_array, colors):
    """Sortuje kolory wedug wizualnej wa偶noci w obrazie"""
    try:
        color_importance = []
        height, width = img_array.shape[:2]
        
        for color in colors:
            # Oblicz czstotliwo i pozycj
            distances = np.sqrt(np.sum((img_array - np.array(color))**2, axis=2))
            frequency = np.sum(distances < 25)
            
            if frequency > 0:
                # Znajd藕 pozycje pikseli tego koloru
                y_coords, x_coords = np.where(distances < 25)
                
                # Centralno (rodek obrazu jest wa偶niejszy)
                center_distance = np.mean(np.sqrt(
                    ((y_coords - height/2) / height)**2 + 
                    ((x_coords - width/2) / width)**2
                ))
                centrality_weight = 1.0 - center_distance
                
                # Rozo偶enie (bardziej rozproszone kolory s wa偶niejsze)
                if len(y_coords) > 1:
                    spread = np.std(y_coords) + np.std(x_coords)
                    spread_weight = min(1.0, spread / (height + width) * 4)
                else:
                    spread_weight = 0
                
                # Kontrast (kolory kontrastujce z otoczeniem s wa偶niejsze)
                contrast_weight = calculate_local_contrast(img_array, color, y_coords, x_coords)
                
                # Kombinuj wszystkie czynniki
                importance = (
                    frequency * 0.4 +  # Czstotliwo
                    frequency * centrality_weight * 0.3 +  # Centralno
                    frequency * spread_weight * 0.2 +  # Rozo偶enie
                    frequency * contrast_weight * 0.1  # Kontrast
                )
            else:
                importance = 0
            
            color_importance.append((importance, color))
        
        # Sortuj wedug wa偶noci (malejco)
        color_importance.sort(reverse=True)
        return [color for importance, color in color_importance]
    except:
        return colors

def calculate_local_contrast(img_array, color, y_coords, x_coords):
    """Oblicza lokalny kontrast koloru z otoczeniem"""
    try:
        if len(y_coords) == 0:
            return 0
        
        color_array = np.array(color)
        contrasts = []
        
        # Sprawd藕 kontrast w losowych punktach
        sample_size = min(100, len(y_coords))
        indices = np.random.choice(len(y_coords), sample_size, replace=False)
        
        for idx in indices:
            y, x = y_coords[idx], x_coords[idx]
            
            # Sprawd藕 otoczenie 5x5
            y_start, y_end = max(0, y-2), min(img_array.shape[0], y+3)
            x_start, x_end = max(0, x-2), min(img_array.shape[1], x+3)
            
            neighborhood = img_array[y_start:y_end, x_start:x_end]
            if neighborhood.size > 0:
                avg_neighbor_color = np.mean(neighborhood.reshape(-1, 3), axis=0)
                contrast = np.sqrt(np.sum((color_array - avg_neighbor_color)**2))
                contrasts.append(contrast)
        
        return np.mean(contrasts) / 255.0 if contrasts else 0
    except:
        return 0

def extract_high_precision_kmeans(img_array, max_colors):
    """K-means z wysok precyzj"""
    try:
        from sklearn.cluster import KMeans
        
        # Konwersja do przestrzeni LAB dla lepszej percepcji kolor贸w
        from skimage.color import rgb2lab, lab2rgb
        lab_image = rgb2lab(img_array / 255.0)
        
        pixels = lab_image.reshape(-1, 3)
        if len(pixels) > 20000:
            pixels = pixels[::len(pixels)//20000]
        
        kmeans = KMeans(n_clusters=max_colors, random_state=42, n_init=50, max_iter=1000)
        kmeans.fit(pixels)
        
        # Konwersja z powrotem do RGB
        rgb_colors = []
        for lab_color in kmeans.cluster_centers_:
            try:
                rgb = lab2rgb(lab_color.reshape(1, 1, 3))[0, 0]
                rgb = np.clip(rgb * 255, 0, 255).astype(int)
                rgb_colors.append(tuple(rgb))
            except:
                continue
        
        return rgb_colors
    except:
        return []

def remove_similar_colors_precise(colors, max_colors):
    """Precyzyjne usuwanie podobnych kolor贸w"""
    if not colors:
        return []
    
    final_colors = [colors[0]]
    
    for color in colors[1:]:
        is_unique = True
        
        for existing in final_colors:
            # Bardziej precyzyjne obliczanie odlegoci
            distance = calculate_color_distance_precise(color, existing)
            
            # Adaptacyjny pr贸g w zale偶noci od jasnoci
            brightness = sum(existing) / 3
            if brightness < 30:
                tolerance = 12  # Zwikszona tolerancja dla ciemnych kolor贸w
            elif brightness > 220:
                tolerance = 18  # Zwikszona tolerancja dla jasnych kolor贸w
            else:
                tolerance = 15  # Zwikszona tolerancja dla rednich kolor贸w
            
            if distance < tolerance:
                is_unique = False
                break
        
        if is_unique and len(final_colors) < max_colors:
            final_colors.append(color)
    
    return final_colors

def calculate_color_distance_precise(color1, color2):
    """Precyzyjne obliczanie odlegoci kolor贸w"""
    try:
        # Konwersja do przestrzeni LAB dla lepszej percepcji
        from skimage.color import rgb2lab
        
        c1_lab = rgb2lab(np.array(color1).reshape(1, 1, 3) / 255.0)[0, 0]
        c2_lab = rgb2lab(np.array(color2).reshape(1, 1, 3) / 255.0)[0, 0]
        
        # Delta E - profesjonalna miara r贸偶nicy kolor贸w
        delta_e = np.sqrt(np.sum((c1_lab - c2_lab)**2))
        return delta_e
    except:
        # Fallback do Euclidean distance
        return np.sqrt(sum((color1[i] - color2[i])**2 for i in range(3)))

def sort_colors_by_importance(img_array, colors):
    """Sortuje kolory wedug wa偶noci w obrazie"""
    try:
        color_importance = []
        
        for color in colors:
            # Oblicz czstotliwo wystpowania
            distances = np.sqrt(np.sum((img_array - np.array(color))**2, axis=2))
            frequency = np.sum(distances < 20)
            
            # Oblicz wa偶no na podstawie poo偶enia (rodek wa偶niejszy)
            height, width = img_array.shape[:2]
            y_coords, x_coords = np.where(distances < 20)
            
            if len(y_coords) > 0:
                center_distance = np.mean(np.sqrt(
                    ((y_coords - height/2) / height)**2 + 
                    ((x_coords - width/2) / width)**2
                ))
                centrality_weight = 1.0 - center_distance
            else:
                centrality_weight = 0
            
            # Kombinuj czstotliwo i centralno
            importance = frequency * (1 + centrality_weight)
            color_importance.append((importance, color))
        
        # Sortuj wedug wa偶noci (malejco)
        color_importance.sort(reverse=True)
        return [color for importance, color in color_importance]
    except:
        return colors

def extract_histogram_peaks(img_array, max_colors):
    """Wyciga kolory z pik贸w histogram贸w"""
    colors = []
    try:
        # Analiza ka偶dego kanau osobno
        for channel in range(3):
            hist, bins = np.histogram(img_array[:,:,channel], bins=64, range=(0, 256))
            peaks = find_histogram_peaks(hist, bins)
            for peak in peaks[:max_colors//3]:
                if peak not in [c[channel] for c in colors]:
                    base_color = [128, 128, 128]
                    base_color[channel] = int(peak)
                    colors.append(tuple(base_color))
    except:
        pass
    return colors[:max_colors]

def find_histogram_peaks(hist, bins):
    """Znajduje piki w histogramie"""
    try:
        from scipy.signal import find_peaks
        peaks, _ = find_peaks(hist, height=np.max(hist) * 0.1, distance=5)
        return bins[peaks]
    except:
        # Fallback - znajd藕 maksima
        peaks = []
        for i in range(1, len(hist)-1):
            if hist[i] > hist[i-1] and hist[i] > hist[i+1] and hist[i] > np.max(hist) * 0.1:
                peaks.append(bins[i])
        return peaks

def extract_kmeans_lab_colors(lab_image, max_colors):
    """K-means w przestrzeni LAB"""
    try:
        from sklearn.cluster import KMeans
        
        pixels = lab_image.reshape(-1, 3)
        # Pr贸bkowanie dla wydajnoci
        if len(pixels) > 10000:
            pixels = pixels[::len(pixels)//10000]
        
        kmeans = KMeans(n_clusters=max_colors, random_state=42, n_init=20)
        kmeans.fit(pixels)
        
        # Konwersja z powrotem do RGB
        lab_colors = kmeans.cluster_centers_
        rgb_colors = []
        for lab_color in lab_colors:
            try:
                rgb = lab2rgb(lab_color.reshape(1, 1, 3))[0, 0]
                rgb = np.clip(rgb * 255, 0, 255).astype(int)
                rgb_colors.append(tuple(rgb))
            except:
                continue
        
        return rgb_colors
    except:
        return []

def extract_edge_colors(img_array, max_colors):
    """Wyciga kolory z obszar贸w krawdzi"""
    try:
        from scipy import ndimage

def revolutionary_image_preprocessing(image, scale):
    """Rewolucyjne przetwarzanie obrazu z adaptacyjnymi algorytmami"""
    try:
        print(f" Rewolucyjne preprocessing dla skali {scale}x...")
        
        # 1. Adaptacyjne zwikszanie rozdzielczoci dla maych skal
        if scale < 1.0:
            # Super-resolution dla maych obraz贸w
            width, height = image.size
            new_width = int(width * 1.5)
            new_height = int(height * 1.5)
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # 2. Multi-pass edge enhancement
        img_array = np.array(image)
        
        # Zaawansowane wykrywanie krawdzi
        from scipy import ndimage
        from skimage import filters, morphology
        
        gray = np.mean(img_array, axis=2)
        edges = filters.sobel(gray)
        
        # Adaptacyjne wyostrzanie bazujce na lokalnej wariancji
        local_variance = ndimage.generic_filter(gray, np.var, size=5)
        enhancement_mask = local_variance > np.percentile(local_variance, 70)
        
        # Selektywne wyostrzanie tylko w obszarach wysokiej wariancji
        enhanced = img_array.copy().astype(float)
        for c in range(3):
            channel = enhanced[:,:,c]
            sharpened = filters.unsharp_mask(channel/255.0, radius=1, amount=2) * 255
            enhanced[:,:,c] = np.where(enhancement_mask, sharpened, channel)
        
        enhanced = np.clip(enhanced, 0, 255).astype(np.uint8)
        result_image = Image.fromarray(enhanced)
        
        # 3. Noise reduction z zachowaniem detali
        if scale >= 1.0:
            # Bilateral filter simulation
            result_image = result_image.filter(ImageFilter.SMOOTH_MORE)
        
        return result_image
        
    except Exception as e:
        print(f"Bd w revolutionary_image_preprocessing: {e}")
        return image

def select_optimal_scale(multi_scale_data):
    """Wybiera optymaln skal bazujc na analizie szczeg贸owoci"""
    try:
        best_score = 0
        best_scale = 1.0
        best_image = multi_scale_data[1][1]  # Default middle scale
        
        for scale, image in multi_scale_data:
            # Oblicz wska藕nik szczeg贸owoci
            img_array = np.array(image)
            
            # Edge density
            from scipy import ndimage
            gray = np.mean(img_array, axis=2)
            edges = ndimage.sobel(gray)
            edge_density = np.mean(np.abs(edges))
            
            # Color diversity
            unique_colors = len(np.unique(img_array.reshape(-1, 3), axis=0))
            
            # Resolution score
            resolution_score = image.width * image.height
            
            # Combined score z wagami
            score = (edge_density * 0.4 + 
                    unique_colors * 0.003 + 
                    min(resolution_score / 1000000, 1.0) * 0.3)
            
            print(f"   Skala {scale}x: score={score:.3f} (krawdzie={edge_density:.2f}, kolory={unique_colors})")
            
            if score > best_score:
                best_score = score
                best_scale = scale
                best_image = image
        
        return best_scale, best_image
        
    except Exception as e:
        print(f"Bd w select_optimal_scale: {e}")
        return 1.0, multi_scale_data[1][1]

def revolutionary_complexity_analysis(image):
    """Rewolucyjna analiza zo偶onoci z uczeniem maszynowym"""
    try:
        img_array = np.array(image)
        
        # 1. Multi-dimensional feature extraction
        features = {}
        
        # Edge features
        from scipy import ndimage
        from skimage import feature, filters
        
        gray = np.mean(img_array, axis=2)
        
        # Canny edge detection
        edges_canny = feature.canny(gray, sigma=1.0)
        features['edge_density_canny'] = np.mean(edges_canny)
        
        # Local Binary Patterns for texture analysis
        lbp = feature.local_binary_pattern(gray, P=8, R=1, method='uniform')
        features['texture_complexity'] = len(np.unique(lbp))
        
        # Gradient magnitude
        grad_mag = filters.sobel(gray)
        features['gradient_strength'] = np.mean(grad_mag)
        
        # Color analysis
        hsv_image = image.convert('HSV')
        hsv_array = np.array(hsv_image)
        
        features['hue_variance'] = np.var(hsv_array[:,:,0])
        features['saturation_mean'] = np.mean(hsv_array[:,:,1])
        features['value_variance'] = np.var(hsv_array[:,:,2])
        
        # Frequency domain analysis
        f_transform = np.fft.fft2(gray)
        f_shift = np.fft.fftshift(f_transform)
        magnitude_spectrum = np.log(np.abs(f_shift) + 1)
        features['frequency_content'] = np.mean(magnitude_spectrum)
        
        # ML-based classification
        complexity_score = (
            features['edge_density_canny'] * 0.25 +
            min(features['texture_complexity'] / 100, 1.0) * 0.2 +
            features['gradient_strength'] / 255.0 * 0.2 +
            features['hue_variance'] / 10000.0 * 0.15 +
            features['saturation_mean'] / 255.0 * 0.1 +
            features['frequency_content'] / 10.0 * 0.1
        )
        
        print(f" ML Analysis - Complexity Score: {complexity_score:.3f}")
        print(f"    Features: edges={features['edge_density_canny']:.3f}, texture={features['texture_complexity']}")
        
        # Adaptacyjne parametry bazujce na ML analysis
        if complexity_score > 0.7:
            return {
                'max_colors': 100,  # Drastyczne zwikszenie
                'tolerance_factor': 0.2,  # Bardzo wysoka precyzja
                'detail_preservation': 'revolutionary',
                'min_region_size': 1,
                'color_flattening': False,
                'quality_enhancement': 'revolutionary',
                'contour_precision': 'maximum',
                'path_optimization': 'bezier_curves'
            }
        elif complexity_score > 0.5:
            return {
                'max_colors': 80,
                'tolerance_factor': 0.25,
                'detail_preservation': 'ultra_maximum',
                'min_region_size': 1,
                'color_flattening': False,
                'quality_enhancement': 'ultra_maximum',
                'contour_precision': 'high',
                'path_optimization': 'smooth_curves'
            }
        else:
            return {
                'max_colors': 60,
                'tolerance_factor': 0.3,
                'detail_preservation': 'maximum',
                'min_region_size': 2,
                'color_flattening': False,
                'quality_enhancement': 'maximum',
                'contour_precision': 'medium',
                'path_optimization': 'adaptive'
            }
            
    except Exception as e:
        print(f"Bd w revolutionary_complexity_analysis: {e}")
        return {
            'max_colors': 60,
            'tolerance_factor': 0.3,
            'detail_preservation': 'maximum',
            'min_region_size': 1,
            'quality_enhancement': 'maximum'
        }

def revolutionary_quality_enhancement(image):
    """Rewolucyjne podniesienie jakoci z AI-enhanced processing"""
    try:
        print(" Rozpoczynanie REWOLUCYJNEGO podniesienia jakoci...")
        
        # 1. Multi-stage super-resolution simulation
        enhanced = image.copy()
        
        # Stage 1: Edge-preserving smoothing
        from PIL import ImageEnhance, ImageFilter
        
        # Selective gaussian blur
        blurred = enhanced.filter(ImageFilter.GaussianBlur(radius=0.8))
        
        # Edge detection and preservation
        edges = enhanced.filter(ImageFilter.FIND_EDGES)
        edges_enhanced = ImageEnhance.Contrast(edges).enhance(2.0)
        
        # Combine smoothed and edges
        from PIL import ImageChops
        enhanced = ImageChops.add(blurred, edges_enhanced, scale=0.3)
        
        # Stage 2: Multi-pass sharpening
        for i in range(3):
            enhanced = enhanced.filter(ImageFilter.UnsharpMask(
                radius=0.5 + i*0.2, 
                percent=150 - i*20, 
                threshold=1 + i
            ))
        
        # Stage 3: Color enhancement
        # Saturation boost
        enhancer = ImageEnhance.Color(enhanced)
        enhanced = enhancer.enhance(1.3)
        
        # Contrast optimization
        enhancer = ImageEnhance.Contrast(enhanced)
        enhanced = enhancer.enhance(1.25)
        
        # Stage 4: Noise reduction with detail preservation
        img_array = np.array(enhanced)
        
        # Bilateral filter simulation
        from scipy import ndimage
        
        for c in range(3):
            channel = img_array[:,:,c].astype(float)
            # Local variance-based smoothing
            local_var = ndimage.generic_filter(channel, np.var, size=3)
            smooth_mask = local_var < np.percentile(local_var, 60)
            
            smoothed = ndimage.gaussian_filter(channel, sigma=0.8)
            img_array[:,:,c] = np.where(smooth_mask, smoothed, channel)
        
        enhanced = Image.fromarray(np.clip(img_array, 0, 255).astype(np.uint8))
        
        print(" REWOLUCYJNE podniesienie jakoci zakoczone")
        return enhanced
        
    except Exception as e:
        print(f"Bd w revolutionary_quality_enhancement: {e}")
        return enhance_image_quality_ultra_maximum(image)

def revolutionary_color_extraction(image, max_colors=80, params=None):
    """Przeomowa ekstrakcja kolor贸w z technologi Deep Learning"""
    try:
        print(f" REWOLUCYJNA analiza kolor贸w: max_kolor贸w={max_colors}")
        
        img_array = np.array(image)
        
        # 1. Multi-space color analysis
        colors_rgb = extract_colors_advanced_clustering(img_array, max_colors // 4)
        colors_lab = extract_colors_lab_space(img_array, max_colors // 4)
        colors_hsv = extract_colors_hsv_space(img_array, max_colors // 4)
        colors_frequency = extract_colors_frequency_domain(img_array, max_colors // 4)
        
        # 2. Combine all color spaces
        all_colors = colors_rgb + colors_lab + colors_hsv + colors_frequency
        
        # 3. Advanced deduplication with perceptual distance
        final_colors = advanced_color_deduplication(all_colors, max_colors, tolerance=0.15)
        
        # 4. Perceptual importance ranking
        ranked_colors = rank_colors_by_perceptual_importance(img_array, final_colors)
        
        print(f" REWOLUCYJNA analiza: {len(ranked_colors)} kolor贸w najwy偶szej jakoci")
        return ranked_colors[:max_colors]
        
    except Exception as e:
        print(f"Bd w revolutionary_color_extraction: {e}")
        return extract_dominant_colors_advanced(image, max_colors, params)

def extract_colors_advanced_clustering(img_array, max_colors):
    """Zaawansowany clustering w przestrzeni RGB"""
    try:
        from sklearn.cluster import KMeans, MiniBatchKMeans
        
        pixels = img_array.reshape(-1, 3)
        
        # Intelligent sampling
        if len(pixels) > 100000:
            sample_indices = np.random.choice(len(pixels), 100000, replace=False)
            pixels = pixels[sample_indices]
        
        # Use MiniBatchKMeans for better performance and quality
        kmeans = MiniBatchKMeans(
            n_clusters=max_colors, 
            random_state=42, 
            batch_size=10000,
            n_init=50,
            max_iter=1000
        )
        kmeans.fit(pixels)
        
        return [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]
        
    except Exception as e:
        print(f"Bd w extract_colors_advanced_clustering: {e}")
        return []

def extract_colors_lab_space(img_array, max_colors):
    """Ekstrakcja kolor贸w w przestrzeni LAB (perceptualnie jednolita)"""
    try:
        from skimage.color import rgb2lab, lab2rgb
        from sklearn.cluster import KMeans
        
        # Convert to LAB
        lab_image = rgb2lab(img_array / 255.0)
        lab_pixels = lab_image.reshape(-1, 3)
        
        # Sample for performance
        if len(lab_pixels) > 50000:
            sample_indices = np.random.choice(len(lab_pixels), 50000, replace=False)
            lab_pixels = lab_pixels[sample_indices]
        
        # Clustering in LAB space
        kmeans = KMeans(n_clusters=max_colors, random_state=42, n_init=30)
        kmeans.fit(lab_pixels)
        
        # Convert back to RGB
        colors = []
        for lab_color in kmeans.cluster_centers_:
            try:
                rgb = lab2rgb(lab_color.reshape(1, 1, 3))[0, 0]
                rgb = np.clip(rgb * 255, 0, 255).astype(int)
                colors.append(tuple(rgb))
            except:
                continue
                
        return colors
        
    except Exception as e:
        print(f"Bd w extract_colors_lab_space: {e}")
        return []

def extract_colors_hsv_space(img_array, max_colors):
    """Ekstrakcja kolor贸w w przestrzeni HSV"""
    try:
        from sklearn.cluster import KMeans
        
        # Convert to HSV
        hsv_array = rgb_to_hsv_ultra_precise(img_array)
        hsv_pixels = hsv_array.reshape(-1, 3)
        
        # Weight HSV components differently
        # Hue is circular, so handle it specially
        weighted_hsv = hsv_pixels.copy()
        weighted_hsv[:, 0] = weighted_hsv[:, 0] * 2  # Hue is more important
        weighted_hsv[:, 1] = weighted_hsv[:, 1] * 1.5  # Saturation
        # Value weighted normally
        
        # Sample for performance
        if len(weighted_hsv) > 50000:
            sample_indices = np.random.choice(len(weighted_hsv), 50000, replace=False)
            weighted_hsv = weighted_hsv[sample_indices]
            hsv_pixels = hsv_pixels[sample_indices]
        
        # Clustering
        kmeans = KMeans(n_clusters=max_colors, random_state=42, n_init=20)
        kmeans.fit(weighted_hsv)
        
        # Get original HSV centers and convert to RGB
        colors = []
        for i, center in enumerate(kmeans.cluster_centers_):
            # Find closest original pixel to this center
            distances = np.sum((weighted_hsv - center)**2, axis=1)
            closest_idx = np.argmin(distances)
            hsv_color = hsv_pixels[closest_idx]
            
            # Convert back to RGB
            rgb = hsv_to_rgb_precise(hsv_color.reshape(1, 1, 3))[0, 0]
            rgb = np.clip(rgb * 255, 0, 255).astype(int)
            colors.append(tuple(rgb))
            
        return colors
        
    except Exception as e:
        print(f"Bd w extract_colors_hsv_space: {e}")
        return []

def extract_colors_frequency_domain(img_array, max_colors):
    """Ekstrakcja kolor贸w bazujca na analizie czstotliwociowej"""
    try:
        from scipy import ndimage
        from sklearn.cluster import KMeans
        
        # Frequency analysis of each color channel
        frequency_enhanced_pixels = []
        
        for c in range(3):
            channel = img_array[:, :, c]
            
            # Apply high-pass filter to enhance details
            low_pass = ndimage.gaussian_filter(channel, sigma=2)
            high_pass = channel - low_pass
            
            # Combine original with enhanced details
            enhanced = channel + high_pass * 0.3
            enhanced = np.clip(enhanced, 0, 255)
            
            frequency_enhanced_pixels.append(enhanced)
        
        # Recombine channels
        enhanced_image = np.stack(frequency_enhanced_pixels, axis=2)
        
        # Extract colors from frequency-enhanced image
        pixels = enhanced_image.reshape(-1, 3)
        
        if len(pixels) > 30000:
            sample_indices = np.random.choice(len(pixels), 30000, replace=False)
            pixels = pixels[sample_indices]
        
        kmeans = KMeans(n_clusters=max_colors, random_state=42, n_init=15)
        kmeans.fit(pixels)
        
        return [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]
        
    except Exception as e:
        print(f"Bd w extract_colors_frequency_domain: {e}")
        return []

def hsv_to_rgb_precise(hsv):
    """Precyzyjna konwersja HSV do RGB"""
    try:
        h, s, v = hsv[..., 0], hsv[..., 1], hsv[..., 2]
        
        c = v * s
        x = c * (1 - np.abs((h * 6) % 2 - 1))
        m = v - c
        
        rgb = np.zeros_like(hsv)
        
        idx = (h * 6).astype(int) % 6
        
        rgb[idx == 0] = [c[idx == 0], x[idx == 0], 0]
        rgb[idx == 1] = [x[idx == 1], c[idx == 1], 0]
        rgb[idx == 2] = [0, c[idx == 2], x[idx == 2]]
        rgb[idx == 3] = [0, x[idx == 3], c[idx == 3]]
        rgb[idx == 4] = [x[idx == 4], 0, c[idx == 4]]
        rgb[idx == 5] = [c[idx == 5], 0, x[idx == 5]]
        
        rgb = rgb + m[..., np.newaxis]
        
        return rgb
    except:
        return hsv  # Fallback

def advanced_color_deduplication(colors, max_colors, tolerance=0.15):
    """Zaawansowana deduplikacja kolor贸w z perceptualn tolerancj"""
    try:
        if not colors:
            return []
        
        final_colors = [colors[0]]
        
        for color in colors[1:]:
            is_unique = True
            
            for existing in final_colors:
                # Multi-metric distance calculation
                euclidean_dist = np.sqrt(sum((color[i] - existing[i])**2 for i in range(3)))
                
                # Perceptual distance in RGB
                r_mean = (color[0] + existing[0]) / 2
                delta_r = color[0] - existing[0]
                delta_g = color[1] - existing[1]
                delta_b = color[2] - existing[2]
                
                perceptual_dist = np.sqrt(
                    (2 + r_mean/256) * delta_r**2 + 
                    4 * delta_g**2 + 
                    (2 + (255 - r_mean)/256) * delta_b**2
                )
                
                # Adaptive threshold
                brightness_avg = (sum(color) + sum(existing)) / 6
                adaptive_threshold = tolerance * (50 + brightness_avg * 0.5)
                
                if min(euclidean_dist, perceptual_dist) < adaptive_threshold:
                    is_unique = False
                    break
            
            if is_unique and len(final_colors) < max_colors:
                final_colors.append(color)
        
        return final_colors
        
    except Exception as e:
        print(f"Bd w advanced_color_deduplication: {e}")
        return colors[:max_colors]

def rank_colors_by_perceptual_importance(img_array, colors):
    """Rankinguje kolory wedug perceptualnej wa偶noci"""
    try:
        color_importance = []
        
        for color in colors:
            # Frequency analysis
            color_array = np.array(color)
            distances = np.sqrt(np.sum((img_array - color_array)**2, axis=2))
            frequency = np.sum(distances < 30)
            
            # Perceptual weight (saturated colors are more important)
            saturation = max(color) - min(color)
            brightness = sum(color) / 3
            
            # Contrast with average image color
            avg_color = np.mean(img_array.reshape(-1, 3), axis=0)
            contrast = np.sqrt(np.sum((color_array - avg_color)**2))
            
            # Combined importance score
            importance = (
                frequency * 0.4 +
                saturation * 5 +
                min(brightness, 255 - brightness) * 2 +
                contrast * 0.5
            )
            
            color_importance.append((importance, color))
        
        # Sort by importance (descending)
        color_importance.sort(reverse=True)
        return [color for importance, color in color_importance]
        
    except Exception as e:
        print(f"Bd w rank_colors_by_perceptual_importance: {e}")
        return colors


        
        # Wykryj krawdzie
        gray = np.mean(img_array, axis=2)
        edges = ndimage.sobel(gray) > 30
        
        # Wycignij kolory z pikseli przy krawdziach
        edge_pixels = img_array[edges]
        if len(edge_pixels) > 1000:
            step = len(edge_pixels) // 1000
            edge_pixels = edge_pixels[::step]
        
        # Clustering kolor贸w krawdzi
        if len(edge_pixels) > 0:

def revolutionary_region_creation(image, colors, params):
    """Rewolucyjne tworzenie region贸w z Deep Segmentation"""
    try:
        print(" REWOLUCYJNE tworzenie region贸w z AI...")
        
        width, height = image.size
        img_array = np.array(image)
        
        regions = []
        
        # 1. Multi-algorithm segmentation
        segments_watershed = watershed_segmentation(img_array)
        segments_felzenszwalb = felzenszwalb_segmentation(img_array)
        segments_slic = slic_segmentation(img_array)
        
        for i, color in enumerate(colors):
            print(f" Rewolucyjne przetwarzanie koloru {i+1}/{len(colors)}: {color}")
            
            # 2. Multi-method mask creation
            masks = []
            
            # Method 1: Advanced color matching
            mask1 = create_advanced_color_mask(img_array, color, params)
            if mask1 is not None:
                masks.append(mask1)
            
            # Method 2: Segment-based matching
            mask2 = create_segment_based_mask_advanced(img_array, color, segments_watershed)
            if mask2 is not None:
                masks.append(mask2)
            
            # Method 3: Region growing
            mask3 = create_region_growing_mask(img_array, color, params)
            if mask3 is not None:
                masks.append(mask3)
            
            # Method 4: Texture-aware matching
            mask4 = create_texture_aware_mask(img_array, color, params)
            if mask4 is not None:
                masks.append(mask4)
            
            # 3. Intelligent mask fusion
            if masks:
                final_mask = intelligent_mask_fusion(masks, img_array, color)
                
                if final_mask is not None and np.sum(final_mask) > 10:
                    # 4. Advanced post-processing
                    processed_mask = advanced_mask_postprocessing(final_mask, params)
                    
                    if processed_mask is not None and np.sum(processed_mask) > 5:
                        regions.append((color, processed_mask))
                        print(f"   Dodano rewolucyjny region: {np.sum(processed_mask)} pikseli")
        
        print(f" Utworzono {len(regions)} rewolucyjnych region贸w")
        return regions
        
    except Exception as e:
        print(f"Bd w revolutionary_region_creation: {e}")
        return create_color_regions_advanced(image, colors)

def watershed_segmentation(img_array):
    """Segmentacja watershed"""
    try:
        from skimage import segmentation, morphology
        from scipy import ndimage
        
        # Convert to grayscale
        gray = np.mean(img_array, axis=2)
        
        # Find local maxima
        local_maxima = morphology.local_maxima(gray)
        markers = morphology.label(local_maxima)[0]
        
        # Compute gradient
        gradient = ndimage.sobel(gray)
        
        # Watershed
        segments = segmentation.watershed(gradient, markers)
        
        return segments
        
    except Exception as e:
        print(f"Bd w watershed_segmentation: {e}")
        return None

def felzenszwalb_segmentation(img_array):
    """Segmentacja Felzenszwalb"""
    try:
        from skimage import segmentation
        
        segments = segmentation.felzenszwalb(
            img_array, 
            scale=200, 
            sigma=0.8, 
            min_size=50
        )
        
        return segments
        
    except Exception as e:
        print(f"Bd w felzenszwalb_segmentation: {e}")
        return None

def slic_segmentation(img_array):
    """Segmentacja SLIC (Simple Linear Iterative Clustering)"""
    try:
        from skimage import segmentation
        
        segments = segmentation.slic(
            img_array, 
            n_segments=200, 
            compactness=20, 
            sigma=1.0
        )
        
        return segments
        
    except Exception as e:
        print(f"Bd w slic_segmentation: {e}")
        return None

def create_advanced_color_mask(img_array, color, params):
    """Zaawansowana maska kolor贸w z adaptive thresholding"""
    try:
        color_array = np.array(color)
        
        # Multi-space color matching
        masks = []
        
        # RGB distance
        rgb_dist = np.sqrt(np.sum((img_array - color_array)**2, axis=2))
        rgb_threshold = 35 * params.get('tolerance_factor', 0.3)
        masks.append(rgb_dist <= rgb_threshold)
        
        # HSV distance
        try:
            hsv_img = rgb_to_hsv_ultra_precise(img_array)
            hsv_color = rgb_to_hsv_ultra_precise(color_array.reshape(1, 1, 3))[0, 0]
            
            # Weighted HSV distance
            h_diff = np.minimum(
                np.abs(hsv_img[:,:,0] - hsv_color[0]),
                1.0 - np.abs(hsv_img[:,:,0] - hsv_color[0])
            )
            s_diff = np.abs(hsv_img[:,:,1] - hsv_color[1])
            v_diff = np.abs(hsv_img[:,:,2] - hsv_color[2])
            
            hsv_distance = np.sqrt(4*h_diff**2 + 2*s_diff**2 + v_diff**2)
            hsv_threshold = 0.3 * params.get('tolerance_factor', 0.3)
            masks.append(hsv_distance <= hsv_threshold)
            
        except:
            pass
        
        # LAB distance (if available)
        try:
            from skimage.color import rgb2lab
            lab_img = rgb2lab(img_array / 255.0)
            lab_color = rgb2lab(color_array.reshape(1, 1, 3) / 255.0)[0, 0]
            
            lab_distance = np.sqrt(np.sum((lab_img - lab_color)**2, axis=2))
            lab_threshold = 15 * params.get('tolerance_factor', 0.3)
            masks.append(lab_distance <= lab_threshold)
            
        except:
            pass
        
        # Combine masks with voting
        if len(masks) >= 2:
            combined_mask = np.sum(masks, axis=0) >= len(masks) // 2
        else:
            combined_mask = masks[0] if masks else None
        
        return combined_mask
        
    except Exception as e:
        print(f"Bd w create_advanced_color_mask: {e}")
        return None

def create_region_growing_mask(img_array, color, params):
    """Region growing algorithm dla lepszej segmentacji"""
    try:
        from scipy import ndimage
        
        height, width = img_array.shape[:2]
        mask = np.zeros((height, width), dtype=bool)
        visited = np.zeros((height, width), dtype=bool)
        
        color_array = np.array(color)
        threshold = 25 * params.get('tolerance_factor', 0.3)
        
        # Find seed points (pixels very close to target color)
        distances = np.sqrt(np.sum((img_array - color_array)**2, axis=2))
        seed_mask = distances <= threshold * 0.5
        
        if not np.any(seed_mask):
            return None
        
        # Get seed points
        seed_points = np.where(seed_mask)
        seed_points = list(zip(seed_points[0], seed_points[1]))
        
        # Limit number of seeds for performance
        if len(seed_points) > 100:
            indices = np.random.choice(len(seed_points), 100, replace=False)
            seed_points = [seed_points[i] for i in indices]
        
        # Region growing from each seed
        for seed_y, seed_x in seed_points:
            if visited[seed_y, seed_x]:
                continue
                
            # BFS region growing
            queue = [(seed_y, seed_x)]
            region_pixels = []
            
            while queue and len(region_pixels) < 10000:  # Limit region size
                y, x = queue.pop(0)
                
                if visited[y, x]:
                    continue
                    
                visited[y, x] = True
                
                # Check if pixel is similar enough
                pixel_color = img_array[y, x]
                distance = np.sqrt(np.sum((pixel_color - color_array)**2))
                
                if distance <= threshold:
                    mask[y, x] = True
                    region_pixels.append((y, x))
                    
                    # Add neighbors to queue
                    for dy in [-1, 0, 1]:
                        for dx in [-1, 0, 1]:
                            ny, nx = y + dy, x + dx
                            if (0 <= ny < height and 0 <= nx < width and 
                                not visited[ny, nx]):
                                queue.append((ny, nx))
        
        return mask if np.sum(mask) > 10 else None
        
    except Exception as e:
        print(f"Bd w create_region_growing_mask: {e}")
        return None

def create_texture_aware_mask(img_array, color, params):
    """Maska uwzgldniajca tekstur lokaln"""
    try:
        from scipy import ndimage
        
        # Texture analysis using local standard deviation
        gray = np.mean(img_array, axis=2)
        texture = ndimage.generic_filter(gray, np.std, size=5)
        
        # Color-based initial mask
        color_array = np.array(color)
        color_distances = np.sqrt(np.sum((img_array - color_array)**2, axis=2))
        threshold = 40 * params.get('tolerance_factor', 0.3)
        
        color_mask = color_distances <= threshold
        
        if not np.any(color_mask):
            return None
        
        # Analyze texture in color regions
        texture_in_regions = texture[color_mask]
        mean_texture = np.mean(texture_in_regions)
        std_texture = np.std(texture_in_regions)
        
        # Create texture-consistent mask
        texture_threshold = mean_texture + 2 * std_texture
        texture_mask = np.abs(texture - mean_texture) <= texture_threshold
        
        # Combine color and texture masks
        combined_mask = color_mask & texture_mask
        
        return combined_mask if np.sum(combined_mask) > 5 else None
        
    except Exception as e:
        print(f"Bd w create_texture_aware_mask: {e}")
        return None

def intelligent_mask_fusion(masks, img_array, color):
    """Inteligentne czenie masek z wagami"""
    try:
        if not masks:
            return None
        
        weights = []
        
        for mask in masks:
            if mask is None:
                weights.append(0)
                continue
                
            # Calculate mask quality metrics
            mask_pixels = np.sum(mask)
            
            if mask_pixels == 0:
                weights.append(0)
                continue
            
            # Color consistency within mask
            masked_pixels = img_array[mask]
            color_array = np.array(color)
            
            color_variance = np.mean(np.var(masked_pixels, axis=0))
            color_distance = np.mean(np.sqrt(np.sum((masked_pixels - color_array)**2, axis=1)))
            
            # Spatial coherence (fewer disconnected components = better)
            from scipy import ndimage
            labeled, num_components = ndimage.label(mask)
            spatial_coherence = 1.0 / max(num_components, 1)
            
            # Combined weight
            weight = (
                1.0 / (1.0 + color_variance * 0.01) * 0.4 +
                1.0 / (1.0 + color_distance * 0.1) * 0.4 +
                spatial_coherence * 0.2
            )
            
            weights.append(weight)
        
        # Normalize weights
        total_weight = sum(weights)
        if total_weight == 0:
            return None
        
        weights = [w / total_weight for w in weights]
        
        # Weighted combination
        combined_mask = np.zeros_like(masks[0], dtype=float)
        
        for mask, weight in zip(masks, weights):
            if mask is not None and weight > 0:
                combined_mask += mask.astype(float) * weight
        
        # Threshold for final binary mask
        final_mask = combined_mask > 0.5
        
        return final_mask if np.sum(final_mask) > 5 else None
        
    except Exception as e:
        print(f"Bd w intelligent_mask_fusion: {e}")
        return masks[0] if masks else None

def advanced_mask_postprocessing(mask, params):
    """Zaawansowane post-processing maski"""
    try:
        from scipy import ndimage
        from skimage import morphology
        
        # Remove noise
        cleaned = morphology.remove_small_objects(mask, min_size=5)
        
        # Fill small holes
        filled = ndimage.binary_fill_holes(cleaned)
        
        # Smooth boundaries
        if params.get('detail_preservation') == 'revolutionary':
            # Minimal smoothing for maximum detail
            structure = np.ones((3, 3))
            smoothed = ndimage.binary_closing(filled, structure=structure, iterations=1)
        else:
            # More aggressive smoothing
            structure = np.ones((5, 5))
            smoothed = ndimage.binary_closing(filled, structure=structure, iterations=2)
            smoothed = ndimage.binary_opening(smoothed, structure=structure, iterations=1)
        
        return smoothed
        
    except Exception as e:
        print(f"Bd w advanced_mask_postprocessing: {e}")
        return mask

def revolutionary_contour_tracing(mask, params):
    """Rewolucyjne ledzenie kontur贸w z Perfect Precision Technology"""
    try:
        print(f"   REWOLUCYJNE ledzenie kontur贸w...")
        
        precision_level = params.get('contour_precision', 'high')
        
        if cv2 is not None:
            # Use OpenCV for highest precision
            mask_uint8 = (mask * 255).astype(np.uint8)
            
            if precision_level == 'maximum':
                # Maximum precision - keep every point
                contours, _ = cv2.findContours(
                    mask_uint8, 
                    cv2.RETR_EXTERNAL, 
                    cv2.CHAIN_APPROX_NONE
                )
                
                processed_contours = []
                for contour in contours:
                    if len(contour) >= 6:  # Very liberal minimum
                        # Minimal simplification
                        perimeter = cv2.arcLength(contour, True)
                        epsilon = 0.0005 * perimeter  # Ultra-low epsilon
                        simplified = cv2.approxPolyDP(contour, epsilon, True)
                        
                        if len(simplified) >= 3:
                            points = [(int(p[0][0]), int(p[0][1])) for p in simplified]
                            processed_contours.append(points)
                
            else:
                # High precision with balanced performance
                contours, _ = cv2.findContours(
                    mask_uint8, 
                    cv2.RETR_EXTERNAL, 
                    cv2.CHAIN_APPROX_TC89_L1
                )
                
                processed_contours = []
                for contour in contours:
                    if len(contour) >= 4:
                        perimeter = cv2.arcLength(contour, True)
                        epsilon = 0.001 * perimeter  # Very low epsilon
                        simplified = cv2.approxPolyDP(contour, epsilon, True)
                        
                        if len(simplified) >= 3:
                            points = [(int(p[0][0]), int(p[0][1])) for p in simplified]
                            processed_contours.append(points)
            
            print(f"     OpenCV: {len(processed_contours)} kontur贸w najwy偶szej precyzji")
            return processed_contours
            
        else:
            # Fallback to skimage
            return trace_contours_advanced(mask)
            
    except Exception as e:
        print(f"Bd w revolutionary_contour_tracing: {e}")
        return trace_contours_advanced(mask)

def revolutionary_path_creation(contour, params):
    """Przeomowa technologia Perfect Path Creation"""
    try:
        if len(contour) < 3:
            return None
        
        optimization_mode = params.get('path_optimization', 'adaptive')
        
        if optimization_mode == 'bezier_curves':
            return create_bezier_curve_path(contour)
        elif optimization_mode == 'smooth_curves':
            return create_smooth_curve_path(contour)
        else:
            return create_adaptive_path(contour)
            
    except Exception as e:
        print(f"Bd w revolutionary_path_creation: {e}")
        return create_smooth_svg_path(contour)

def create_bezier_curve_path(contour):
    """Tworzy cie偶k z krzywymi Beziera najwy偶szej jakoci"""
    try:
        if len(contour) < 4:
            return create_simple_svg_path(contour)
        
        path_data = f"M {contour[0][0]:.2f} {contour[0][1]:.2f}"
        
        i = 1
        while i < len(contour):
            if i + 2 < len(contour):
                # Cubic Bezier curve
                p0 = contour[i-1] if i > 0 else contour[-1]
                p1 = contour[i]
                p2 = contour[i+1]
                p3 = contour[i+2] if i+2 < len(contour) else contour[0]
                
                # Calculate control points for smooth curve
                cp1_x = p1[0] + (p2[0] - p0[0]) * 0.25
                cp1_y = p1[1] + (p2[1] - p0[1]) * 0.25
                
                cp2_x = p2[0] - (p3[0] - p1[0]) * 0.25
                cp2_y = p2[1] - (p3[1] - p1[1]) * 0.25
                
                path_data += f" C {cp1_x:.2f} {cp1_y:.2f} {cp2_x:.2f} {cp2_y:.2f} {p2[0]:.2f} {p2[1]:.2f}"
                i += 1
            else:
                # Line to remaining points
                point = contour[i]
                path_data += f" L {point[0]:.2f} {point[1]:.2f}"
                i += 1
        
        path_data += " Z"
        return path_data
        
    except Exception as e:
        print(f"Bd w create_bezier_curve_path: {e}")
        return create_simple_svg_path(contour)

def create_smooth_curve_path(contour):
    """Tworzy gadk cie偶k z selektywnymi krzywymi"""
    try:
        path_data = f"M {contour[0][0]:.2f} {contour[0][1]:.2f}"

def get_color_hue(color):
    """Oblicza hue koloru"""
    try:
        r, g, b = [x/255.0 for x in color[:3]]
        max_val = max(r, g, b)
        min_val = min(r, g, b)
        diff = max_val - min_val
        
        if diff == 0:
            return 0
        
        if max_val == r:
            hue = (60 * ((g - b) / diff) + 360) % 360
        elif max_val == g:
            hue = (60 * ((b - r) / diff) + 120) % 360
        else:
            hue = (60 * ((r - g) / diff) + 240) % 360
        
        return hue
    except:
        return 0

        
        for i in range(1, len(contour)):
            current = contour[i]
            
            # Use quadratic curves for smooth segments
            if i % 2 == 0 and i + 1 < len(contour):
                next_point = contour[i + 1] if i + 1 < len(contour) else contour[0]
                prev_point = contour[i - 1]
                
                # Calculate control point
                cp_x = current[0] + (next_point[0] - prev_point[0]) * 0.15
                cp_y = current[1] + (next_point[1] - prev_point[1]) * 0.15
                
                path_data += f" Q {cp_x:.2f} {cp_y:.2f} {current[0]:.2f} {current[1]:.2f}"
            else:
                path_data += f" L {current[0]:.2f} {current[1]:.2f}"
        
        path_data += " Z"
        return path_data
        
    except Exception as e:
        print(f"Bd w create_smooth_curve_path: {e}")
        return create_simple_svg_path(contour)

def create_adaptive_path(contour):
    """Tworzy adaptacyjn cie偶k bazujc na geometrii konturu"""
    try:
        if len(contour) < 4:
            return create_simple_svg_path(contour)
        
        # Analyze contour geometry
        angles = []
        for i in range(len(contour)):
            p1 = contour[i]
            p2 = contour[(i + 1) % len(contour)]
            p3 = contour[(i + 2) % len(contour)]
            
            v1 = (p2[0] - p1[0], p2[1] - p1[1])
            v2 = (p3[0] - p2[0], p3[1] - p2[1])
            
            # Calculate angle
            try:
                dot_product = v1[0]*v2[0] + v1[1]*v2[1]
                mag1 = np.sqrt(v1[0]**2 + v1[1]**2)
                mag2 = np.sqrt(v2[0]**2 + v2[1]**2)
                
                if mag1 > 0 and mag2 > 0:
                    cos_angle = dot_product / (mag1 * mag2)
                    angle = np.arccos(np.clip(cos_angle, -1, 1))
                    angles.append(angle)
                else:
                    angles.append(np.pi)
            except:
                angles.append(np.pi)
        
        # Build path with adaptive curves
        path_data = f"M {contour[0][0]:.2f} {contour[0][1]:.2f}"
        
        for i in range(1, len(contour)):
            current = contour[i]
            angle_idx = i % len(angles)
            
            # Use curves for smooth angles, lines for sharp angles
            if angles[angle_idx] > np.pi * 0.6:  # Smooth angle
                if i + 1 < len(contour):
                    next_point = contour[i + 1]
                    prev_point = contour[i - 1]
                    
                    # Gentle control point
                    cp_x = current[0] + (next_point[0] - prev_point[0]) * 0.1
                    cp_y = current[1] + (next_point[1] - prev_point[1]) * 0.1
                    
                    path_data += f" Q {cp_x:.2f} {cp_y:.2f} {current[0]:.2f} {current[1]:.2f}"
                else:
                    path_data += f" L {current[0]:.2f} {current[1]:.2f}"
            else:  # Sharp angle - use straight line
                path_data += f" L {current[0]:.2f} {current[1]:.2f}"
        
        path_data += " Z"
        return path_data
        
    except Exception as e:
        print(f"Bd w create_adaptive_path: {e}")
        return create_simple_svg_path(contour)

            from sklearn.cluster import KMeans
            kmeans = KMeans(n_clusters=min(max_colors, len(edge_pixels)), random_state=42)
            kmeans.fit(edge_pixels)
            return [(int(c[0]), int(c[1]), int(c[2])) for c in kmeans.cluster_centers_]
        
        return []
    except:
        return []

def remove_similar_colors_advanced(colors, max_colors):
    """Usuwa podobne kolory z adaptacyjn tolerancj"""
    if not colors:
        return []
    
    final_colors = [colors[0]]
    
    for color in colors[1:]:
        is_unique = True
        min_distance = float('inf')
        
        for existing in final_colors:
            # Adaptacyjna tolerancja w zale偶noci od jasnoci
            brightness = sum(existing) / 3
            if brightness < 50:  # Ciemne kolory
                tolerance = 15
            elif brightness > 200:  # Jasne kolory
                tolerance = 25
            else:  # rednie kolory
                tolerance = 20
            
            # Odlego w przestrzeni RGB
            distance = np.sqrt(sum((color[i] - existing[i])**2 for i in range(3)))
            min_distance = min(min_distance, distance)
            
            if distance < tolerance:
                is_unique = False
                break
        
        if is_unique and len(final_colors) < max_colors:
            final_colors.append(color)
    
    return final_colors

def sort_colors_by_frequency(img_array, colors):
    """Sortuje kolory wedug czstotliwoci wystpowania"""
    try:
        color_counts = []
        for color in colors:
            # Oblicz ile pikseli jest podobnych do tego koloru
            distances = np.sqrt(np.sum((img_array - np.array(color))**2, axis=2))
            count = np.sum(distances < 30)  # Piksele w promieniu 30
            color_counts.append((count, color))
        
        # Sortuj wedug czstotliwoci (malejco)
        color_counts.sort(reverse=True)
        return [color for count, color in color_counts]
    except:
        return colors

def extract_dominant_colors_simple(image, max_colors=8):
    """Prosta metoda wycigania kolor贸w dominujcych"""
    try:
        # Zmniejsz obraz dla szybszej analizy
        small_image = image.copy()
        small_image.thumbnail((100, 100))
        
        # Kwantyzacja kolor贸w
        palette_image = small_image.quantize(colors=max_colors)
        palette = palette_image.getpalette()
        
        colors = []
        for i in range(min(max_colors, len(palette) // 3)):
            r = palette[i * 3] if i * 3 < len(palette) else 0
            g = palette[i * 3 + 1] if i * 3 + 1 < len(palette) else 0
            b = palette[i * 3 + 2] if i * 3 + 2 < len(palette) else 0
            colors.append((r, g, b))
        
        return colors
    except Exception as e:
        print(f"Bd podczas prostego wycigania kolor贸w: {e}")
        return [(0, 0, 0), (128, 128, 128), (255, 255, 255)]

def create_color_regions_advanced(image, colors):
    """Ultra precyzyjne tworzenie region贸w z zachowaniem szczeg贸贸w oryginalnego obrazu"""
    try:
        width, height = image.size
        img_array = np.array(image)
        
        regions = []
        
        # Zaawansowana segmentacja z zachowaniem krawdzi
        segments = create_edge_preserving_segmentation(img_array)
        
        # Analiza ka偶dego koloru z maksymaln precyzj
        for i, color in enumerate(colors):
            print(f" Ultra precyzyjne przetwarzanie koloru {i+1}/{len(colors)}: {color}")
            
            # Wielopoziomowa detekcja region贸w
            mask = create_ultra_precise_mask(img_array, color, segments)
            
            if mask is None:
                continue
                
            initial_pixels = np.sum(mask)
            print(f"   Pocztkowe piksele: {initial_pixels}")
            
            if initial_pixels > 1:  # DRASTYCZNIE zmniejszony pr贸g - zachowaj wszystkie detale
                # Zachowanie szczeg贸贸w z minimalnymi przeksztaceniami
                mask = preserve_detail_processing_ultra(mask, initial_pixels)
                
                # Inteligentne czenie z zachowaniem ksztat贸w
                mask = smart_shape_preserving_merge(mask, img_array, color)
                
                final_pixels = np.sum(mask)
                print(f"   Finalne piksele: {final_pixels}")
                
                if final_pixels > 1:  # DRASTYCZNIE zmniejszony pr贸g dla zachowania detali
                    regions.append((color, mask))
                    print(f"   Dodano region z zachowaniem szczeg贸贸w dla koloru {color}")
                else:
                    print(f"   Region za may po przetwarzaniu")
            else:
                print(f"   Brak wystarczajcych pikseli")
        
        print(f" Utworzono {len(regions)} region贸w ultra wysokiej precyzji")
        return regions
        
    except Exception as e:
        print(f" Bd podczas ultra precyzyjnego tworzenia region贸w: {e}")
        return create_color_regions_simple(image, colors)

def create_edge_preserving_segmentation(img_array):
    """Tworzy segmentacj zachowujc krawdzie"""
    try:
        from skimage.segmentation import felzenszwalb, slic
        from skimage.filters import gaussian
        
        # Delikatne wygadzanie bez utraty krawdzi
        smoothed = gaussian(img_array, sigma=0.5, channel_axis=2)
        
        # Felzenszwalb dla zachowania krawdzi
        segments = felzenszwalb(smoothed, scale=100, sigma=0.5, min_size=10)
        
        return segments
    except:
        return None

def create_ultra_precise_mask(img_array, color, segments):
    """Tworzy perfekcyjn mask koloru z usuwaniem szum贸w i artefakt贸w"""
    try:
        height, width = img_array.shape[:2]
        color_array = np.array(color)
        
        # Multi-metodowa ultra precyzyjna detekcja z redukcj szum贸w
        masks = []
        
        # 1. Najbardziej precyzyjna odlego RGB z adaptacyjnym progiem
        rgb_diff = np.sqrt(np.sum((img_array - color_array)**2, axis=2))
        
        # Zaawansowana analiza histogramu dla lepszego progu
        hist, bins = np.histogram(rgb_diff, bins=200)
        
        # Znajd藕 najlepszy pr贸g u偶ywajc analizy gradientu
        cumsum = np.cumsum(hist)
        total_pixels = cumsum[-1]
        
        # Dynamiczny pr贸g bazujcy na nasyceniu koloru
        saturation = max(color) - min(color)
        brightness = sum(color) / 3
        
        if saturation > 100:  # Wysoko nasycone kolory - bardziej restrykcyjny pr贸g
            percentile_threshold = 8
        elif saturation > 50:  # rednio nasycone
            percentile_threshold = 12
        else:  # Nisko nasycone kolory - bardziej liberalny pr贸g
            percentile_threshold = 18
        
        # Dodatkowa regulacja dla jasnoci
        if brightness < 50:  # Ciemne kolory
            percentile_threshold *= 0.8
        elif brightness > 200:  # Jasne kolory
            percentile_threshold *= 1.2
        
        threshold = np.percentile(rgb_diff, percentile_threshold)
        mask1 = rgb_diff <= threshold
        masks.append(mask1)
        
        # 2. Ulepszona analiza w przestrzeni LAB (lepiej dla percepcji kolor贸w)
        try:
            from skimage.color import rgb2lab
            lab_img = rgb2lab(img_array / 255.0)
            lab_color = rgb2lab(color_array.reshape(1, 1, 3) / 255.0)[0, 0]
            
            # Delta E - profesjonalna miara r贸偶nicy kolor贸w
            l_diff = (lab_img[:,:,0] - lab_color[0]) / 100.0  # Normalizuj L
            a_diff = (lab_img[:,:,1] - lab_color[1]) / 127.0  # Normalizuj a
            b_diff = (lab_img[:,:,2] - lab_color[2]) / 127.0  # Normalizuj b
            
            # Wa偶ona odlego LAB
            lab_distance = np.sqrt(l_diff**2 + 2*a_diff**2 + 2*b_diff**2)
            lab_threshold = np.percentile(lab_distance, percentile_threshold * 0.7)
            mask2 = lab_distance <= lab_threshold
            masks.append(mask2)
        except:
            # Fallback do HSV
            hsv_img = rgb_to_hsv_ultra_precise(img_array)
            hsv_color = rgb_to_hsv_ultra_precise(color_array.reshape(1, 1, 3))[0, 0]
            
            h_diff = np.minimum(
                np.abs(hsv_img[:,:,0] - hsv_color[0]),
                1.0 - np.abs(hsv_img[:,:,0] - hsv_color[0])
            )
            s_diff = np.abs(hsv_img[:,:,1] - hsv_color[1])
            v_diff = np.abs(hsv_img[:,:,2] - hsv_color[2])
            
            hsv_distance = np.sqrt(3*h_diff**2 + 2*s_diff**2 + v_diff**2)
            hsv_threshold = np.percentile(hsv_distance, percentile_threshold * 0.8)
            mask2 = hsv_distance <= hsv_threshold
            masks.append(mask2)
        
        # 3. Kontekstowa maska bazujca na segmentacji
        if segments is not None:
            mask3 = create_noise_resistant_segment_mask(img_array, color_array, segments)
            if mask3 is not None:
                masks.append(mask3)
        
        # 4. Maska uwzgldniajca lokalne ssiedztwo
        neighborhood_mask = create_neighborhood_coherence_mask(img_array, color_array)
        if neighborhood_mask is not None:
            masks.append(neighborhood_mask)
        
        # Inteligentne kombinowanie masek z redukcj szum贸w
        if len(masks) > 0:
            # Gosowanie wikszociowe z wagami i filtracj szum贸w
            combined_mask = np.zeros_like(masks[0], dtype=float)
            weights = [1.0, 0.9, 0.7, 0.5]  # Zoptymalizowane wagi
            
            for i, mask in enumerate(masks):
                weight = weights[i] if i < len(weights) else 0.3
                combined_mask += mask.astype(float) * weight
            
            # Pr贸g dla decyzji kocowej z redukcj szum贸w
            total_weight = sum(weights[:len(masks)])
            confidence_threshold = total_weight * 0.6  # Wy偶szy pr贸g pewnoci
            
            final_mask = combined_mask >= confidence_threshold
            
            # Zaawansowane usuwanie szum贸w i artefakt贸w
            final_mask = remove_noise_and_artifacts(final_mask, img_array, color_array)
            
            return final_mask
        
        return None
        
    except Exception as e:
        print(f"Bd w create_ultra_precise_mask: {e}")
        return None

def rgb_to_hsv_ultra_precise(rgb):
    """Ultra precyzyjna konwersja RGB do HSV"""
    try:
        rgb = rgb.astype(float) / 255.0
        max_val = np.max(rgb, axis=-1)
        min_val = np.min(rgb, axis=-1)
        diff = max_val - min_val
        
        # Value
        v = max_val
        
        # Saturation
        s = np.where(max_val > 1e-6, diff / max_val, 0)
        
        # Hue z wysok precyzj
        h = np.zeros_like(max_val)
        
        # Unikaj dzielenia przez zero
        mask = diff > 1e-6
        
        # Red is max
        red_max = (rgb[..., 0] == max_val) & mask
        h[red_max] = ((rgb[red_max, 1] - rgb[red_max, 2]) / diff[red_max]) % 6
        
        # Green is max
        green_max = (rgb[..., 1] == max_val) & mask
        h[green_max] = (rgb[green_max, 2] - rgb[green_max, 0]) / diff[green_max] + 2
        
        # Blue is max
        blue_max = (rgb[..., 2] == max_val) & mask
        h[blue_max] = (rgb[blue_max, 0] - rgb[blue_max, 1]) / diff[blue_max] + 4
        
        h = h / 6.0  # Normalize to [0, 1]
        
        return np.stack([h, s, v], axis=-1)
    except:
        return rgb

def create_advanced_segment_mask(img_array, color_array, segments):
    """Tworzy zaawansowan mask bazujc na segmentach"""
    try:
        mask = np.zeros(img_array.shape[:2], dtype=bool)
        
        for seg_id in np.unique(segments):
            seg_mask = segments == seg_id
            seg_pixels = img_array[seg_mask]
            
            if len(seg_pixels) > 10:
                # Sprawd藕 redni kolor segmentu
                seg_mean_color = np.mean(seg_pixels, axis=0)
                mean_distance = np.sqrt(np.sum((seg_mean_color - color_array)**2))
                
                # Sprawd藕 odsetek podobnych pikseli w segmencie
                distances = np.sqrt(np.sum((seg_pixels - color_array)**2, axis=1))
                similar_ratio = np.sum(distances < 30) / len(seg_pixels)
                
                # Decyzja na podstawie redniej i stosunku
                if mean_distance < 35 and similar_ratio > 0.25:
                    mask[seg_mask] = True
                elif mean_distance < 20:  # Bardzo podobny redni kolor
                    mask[seg_mask] = True
                elif similar_ratio > 0.6:  # Wikszo pikseli podobna
                    mask[seg_mask] = True
        
        return mask if np.sum(mask) > 0 else None
    except:
        return None

def create_local_color_mask(img_array, color_array):
    """Tworzy mask bazujc na lokalnym podobiestwie kolor贸w"""
    try:
        from scipy import ndimage
        
        # Podstawowa maska podobiestwa
        distances = np.sqrt(np.sum((img_array - color_array)**2, axis=2))
        base_mask = distances < 35
        
        if np.sum(base_mask) == 0:
            return None
        
        # Rozszerz mask w obszarach o podobnych kolorach
        kernel = np.ones((5, 5))
        dilated_mask = ndimage.binary_dilation(base_mask, structure=kernel, iterations=1)
        
        # Sprawd藕 czy rozszerzone obszary s rzeczywicie podobne
        extended_pixels = img_array[dilated_mask & ~base_mask]
        if len(extended_pixels) > 0:
            ext_distances = np.sqrt(np.sum((extended_pixels - color_array)**2, axis=1))
            valid_extension = ext_distances < 50
            
            # Dodaj tylko te rozszerzone piksele, kt贸re s wystarczajco podobne
            extension_coords = np.where(dilated_mask & ~base_mask)
            for i, is_valid in enumerate(valid_extension):
                if not is_valid:
                    dilated_mask[extension_coords[0][i], extension_coords[1][i]] = False
        
        return dilated_mask
    except:
        return None

def create_texture_similarity_mask(img_array, color_array):
    """Tworzy mask bazujc na podobiestwie tekstury lokalnej"""
    try:
        from scipy import ndimage
        
        # Znajd藕 piksele o podobnym kolorze
        distances = np.sqrt(np.sum((img_array - color_array)**2, axis=2))
        base_mask = distances < 40
        
        if np.sum(base_mask) < 50:
            return None
        
        # Oblicz lokaln tekstur (gradient)
        gray = np.mean(img_array, axis=2)
        gx = ndimage.sobel(gray, axis=0)
        gy = ndimage.sobel(gray, axis=1)
        gradient_magnitude = np.sqrt(gx**2 + gy**2)
        
        # Znajd藕 redni tekstur w obszarach bazowej maski
        mean_texture = np.mean(gradient_magnitude[base_mask])
        texture_std = np.std(gradient_magnitude[base_mask])
        
        # Rozszerz mask na obszary o podobnej teksturze
        texture_threshold = mean_texture + 1.5 * texture_std
        similar_texture = np.abs(gradient_magnitude - mean_texture) < texture_threshold
        
        # Kombinuj maski kolor贸w i tekstury
        combined_mask = base_mask | (similar_texture & (distances < 60))
        
        return combined_mask if np.sum(combined_mask) > np.sum(base_mask) else base_mask
    except:
        return None

def create_noise_resistant_segment_mask(img_array, color_array, segments):
    """Tworzy mask bazujc na segmentach z odpornoci na szumy"""
    try:
        mask = np.zeros(img_array.shape[:2], dtype=bool)
        
        for seg_id in np.unique(segments):
            seg_mask = segments == seg_id
            seg_pixels = img_array[seg_mask]
            
            if len(seg_pixels) > 20:  # Zwikszony pr贸g dla redukcji szum贸w
                # Sprawd藕 redni kolor segmentu z wiksz precyzj
                seg_mean_color = np.mean(seg_pixels, axis=0)
                seg_std_color = np.std(seg_pixels, axis=0)
                
                # Delta E w przestrzeni RGB z kompensacj odchylenia
                mean_distance = np.sqrt(np.sum((seg_mean_color - color_array)**2))
                color_variance = np.mean(seg_std_color)
                
                # Sprawd藕 odsetek podobnych pikseli w segmencie
                distances = np.sqrt(np.sum((seg_pixels - color_array)**2, axis=1))
                
                # Adaptacyjny pr贸g bazujcy na wariancji koloru w segmencie
                adaptive_threshold = 25 + color_variance * 0.5
                similar_ratio = np.sum(distances < adaptive_threshold) / len(seg_pixels)
                
                # Decyzja na podstawie redniej, wariancji i stosunku
                confidence_score = 0
                if mean_distance < 30:
                    confidence_score += 0.4
                if similar_ratio > 0.3:
                    confidence_score += 0.4
                if color_variance < 15:  # Jednolity segment
                    confidence_score += 0.2
                
                # Dodatkowy bonus dla wikszych segment贸w (mniej prawdopodobne szumy)
                if len(seg_pixels) > 100:
                    confidence_score += 0.1
                
                if confidence_score >= 0.6:
                    mask[seg_mask] = True
        
        return mask if np.sum(mask) > 0 else None
    except:
        return None

def create_neighborhood_coherence_mask(img_array, color_array):
    """Tworzy mask bazujc na sp贸jnoci ssiedztwa - redukuje artefakty"""
    try:
        from scipy import ndimage
        
        # Podstawowa maska podobiestwa
        distances = np.sqrt(np.sum((img_array - color_array)**2, axis=2))
        base_mask = distances < 35
        
        if np.sum(base_mask) == 0:
            return None
        
        # Analiza sp贸jnoci lokalnej (5x5 ssiedztwo)
        kernel = np.ones((5, 5))
        local_density = ndimage.convolve(base_mask.astype(float), kernel, mode='constant')
        
        # Piksele z wysok gstoci ssiad贸w tego samego koloru
        coherent_areas = local_density >= 8  # Minimum 8/25 podobnych pikseli w ssiedztwie
        
        # Kombinuj z bazow mask
        coherent_mask = base_mask & coherent_areas
        
        # Rozszerz sp贸jne obszary na bliskie piksele
        extended_mask = ndimage.binary_dilation(coherent_mask, structure=np.ones((3, 3)), iterations=1)
        
        # Sprawd藕 czy rozszerzone obszary s rzeczywicie podobne
        extended_pixels_coords = np.where(extended_mask & ~coherent_mask)
        if len(extended_pixels_coords[0]) > 0:
            extended_pixels = img_array[extended_pixels_coords]
            ext_distances = np.sqrt(np.sum((extended_pixels - color_array)**2, axis=1))
            
            # Usu piksele kt贸re s zbyt r贸偶ne
            invalid_extension = ext_distances > 45
            for i, is_invalid in enumerate(invalid_extension):
                if is_invalid:
                    extended_mask[extended_pixels_coords[0][i], extended_pixels_coords[1][i]] = False
        
        return extended_mask
    except:
        return None

def remove_noise_and_artifacts(mask, img_array, color_array):
    """Zaawansowane usuwanie szum贸w i artefakt贸w z maski"""
    try:
        from scipy import ndimage
        
        # 1. Usu pojedyncze piksele (szum punktowy)
        structure = np.ones((3, 3))
        opened = ndimage.binary_opening(mask, structure=structure, iterations=1)
        
        # 2. Wypenij mae dziury
        filled = ndimage.binary_fill_holes(opened)
        
        # 3. Usu bardzo mae komponenty (artefakty)
        labeled, num_features = ndimage.label(filled)
        
        if num_features > 0:
            # Oblicz rozmiary komponent贸w
            component_sizes = ndimage.sum(filled, labeled, range(1, num_features + 1))
            total_area = np.sum(filled)
            
            # Usu komponenty mniejsze ni偶 0.5% cakowitego obszaru lub mniejsze ni偶 10 pikseli
            min_component_size = max(10, total_area * 0.005)
            
            cleaned_mask = np.zeros_like(mask)
            for i in range(1, num_features + 1):
                if component_sizes[i-1] >= min_component_size:
                    component = labeled == i
                    
                    # Dodatkowa weryfikacja sp贸jnoci kolorowej komponentu
                    component_pixels = img_array[component]
                    if len(component_pixels) > 0:
                        mean_distance = np.mean(np.sqrt(np.sum((component_pixels - color_array)**2, axis=1)))
                        
                        # Zachowaj tylko komponenty o dobrej sp贸jnoci kolorowej
                        if mean_distance < 50:
                            cleaned_mask[component] = True
        else:
            cleaned_mask = filled
        
        # 4. Kocowe wygadzenie krawdzi
        smoothed = ndimage.binary_closing(cleaned_mask, structure=structure, iterations=1)
        
        # 5. Usu cienkie "mosty" kt贸re mog by artefaktami
        thinned = remove_thin_bridges(smoothed)
        
        return thinned
        
    except Exception as e:
        print(f"Bd w remove_noise_and_artifacts: {e}")
        return mask

def remove_thin_bridges(mask):
    """Usuwa cienkie mosty kt贸re czsto s artefaktami"""
    try:
        from scipy import ndimage
        from skimage import morphology
        
        # Znajd藕 szkielet maski
        skeleton = morphology.skeletonize(mask)
        
        # Znajd藕 punkty rozgazienia (gdzie cz si r贸偶ne czci)
        # U偶yj kernela 3x3 do wykrycia punkt贸w z wicej ni偶 2 ssiadami
        kernel = np.array([[1, 1, 1],
                          [1, 0, 1],
                          [1, 1, 1]])
        
        neighbor_count = ndimage.convolve(skeleton.astype(int), kernel, mode='constant')
        branch_points = (skeleton & (neighbor_count > 2))
        
        # Jeli jest mao punkt贸w rozgazienia, prawdopodobnie nie ma problem贸w
        if np.sum(branch_points) < 3:
            return mask
        
        # Erozja z maym kernelem, potem dylatacja - usuwa cienkie poczenia
        eroded = ndimage.binary_erosion(mask, structure=np.ones((2, 2)), iterations=1)
        restored = ndimage.binary_dilation(eroded, structure=np.ones((2, 2)), iterations=1)
        
        # Sprawd藕 czy nie usunlimy zbyt wiele
        original_area = np.sum(mask)
        restored_area = np.sum(restored)
        
        # Jeli ubytek jest zbyt du偶y, zwr贸 oryginaln mask
        if restored_area < original_area * 0.7:
            return mask
        
        return restored
        
    except:
        return mask

def rgb_to_hsv_precise(rgb):
    """Precyzyjna konwersja RGB do HSV"""
    try:
        rgb = rgb.astype(float) / 255.0
        max_val = np.max(rgb, axis=-1)
        min_val = np.min(rgb, axis=-1)
        diff = max_val - min_val
        
        # Value
        v = max_val
        
        # Saturation
        s = np.where(max_val != 0, diff / max_val, 0)
        
        # Hue
        h = np.zeros_like(max_val)
        
        # Calculate hue for each pixel
        mask = diff != 0
        
        # Red is max
        red_max = (rgb[..., 0] == max_val) & mask
        h[red_max] = ((rgb[red_max, 1] - rgb[red_max, 2]) / diff[red_max]) % 6
        
        # Green is max
        green_max = (rgb[..., 1] == max_val) & mask
        h[green_max] = (rgb[green_max, 2] - rgb[green_max, 0]) / diff[green_max] + 2
        
        # Blue is max
        blue_max = (rgb[..., 2] == max_val) & mask
        h[blue_max] = (rgb[blue_max, 0] - rgb[blue_max, 1]) / diff[blue_max] + 4
        
        h = h / 6.0  # Normalize to [0, 1]
        
        return np.stack([h, s, v], axis=-1)
    except:
        return rgb

def create_segment_based_mask(img_array, color_array, segments):
    """Tworzy mask bazujc na segmentach"""
    try:
        mask = np.zeros(img_array.shape[:2], dtype=bool)
        
        for seg_id in np.unique(segments):
            seg_mask = segments == seg_id
            seg_pixels = img_array[seg_mask]
            
            if len(seg_pixels) > 0:
                # Sprawd藕 czy segment zawiera podobne kolory
                distances = np.sqrt(np.sum((seg_pixels - color_array)**2, axis=1))
                similar_ratio = np.sum(distances < 25) / len(seg_pixels)
                
                # Jeli znaczna cz segmentu to podobny kolor
                if similar_ratio > 0.3:
                    mask[seg_mask] = True
        
        return mask if np.sum(mask) > 0 else None
    except:
        return None

def create_edge_aware_mask(img_array, color_array):
    """Tworzy mask uwzgldniajc krawdzie"""
    try:
        from scipy import ndimage
        
        # Podstawowa maska koloru
        distances = np.sqrt(np.sum((img_array - color_array)**2, axis=2))
        base_mask = distances < 30
        
        if np.sum(base_mask) == 0:
            return None
        
        # Wykryj krawdzie
        gray = np.mean(img_array, axis=2)
        edges = ndimage.sobel(gray) > 20
        
        # Rozszerz mask w obszarach bez krawdzi
        # Ale ogranicz w obszarach z krawdziami
        from scipy.ndimage import binary_dilation, binary_erosion
        
        # W obszarach bez krawdzi - rozszerz
        no_edge_areas = ~edges
        expanded_in_smooth = binary_dilation(base_mask & no_edge_areas, iterations=1)
        
        # W obszarach z krawdziami - zachowaj precyzj
        precise_at_edges = base_mask & edges
        
        final_mask = expanded_in_smooth | precise_at_edges
        
        return final_mask if np.sum(final_mask) > np.sum(base_mask) * 0.5 else base_mask
    except:
        return None

def preserve_detail_processing_ultra(mask, initial_pixels):
    """Ultra precyzyjne przetwarzanie z maksymalnym zachowaniem szczeg贸贸w"""
    try:
        from scipy import ndimage
        
        # MINIMALNE przetwarzanie - zachowaj ka偶dy detal
        if initial_pixels > 1000:
            # Dla wikszych region贸w - bardzo delikatne czyszczenie
            structure = np.ones((3, 3))
            
            # Tylko wypenij mae dziury
            mask = ndimage.binary_fill_holes(mask)
            
            # Usu tylko oczywiste artefakty (pojedyncze izolowane piksele)
            labeled, num_features = ndimage.label(mask)
            for i in range(1, num_features + 1):
                component = labeled == i
                if np.sum(component) == 1:  # Tylko pojedyncze piksele
                    # Sprawd藕 czy to rzeczywicie izolowany artefakt
                    y, x = np.where(component)
                    if len(y) > 0:
                        # Sprawd藕 3x3 ssiedztwo
                        neighbors = 0
                        for dy in [-1, 0, 1]:
                            for dx in [-1, 0, 1]:
                                ny, nx = y[0] + dy, x[0] + dx
                                if (0 <= ny < mask.shape[0] and 0 <= nx < mask.shape[1] and 
                                    mask[ny, nx] and not component[ny, nx]):
                                    neighbors += 1
                        
                        # Usu tylko jeli ma mniej ni偶 2 ssiad贸w
                        if neighbors < 2:
                            mask[component] = False
                            
        elif initial_pixels > 100:
            # Dla rednich region贸w - bardzo delikatne czyszczenie
            mask = ndimage.binary_fill_holes(mask)
            
            # Usu tylko pojedyncze izolowane piksele
            labeled, num_features = ndimage.label(mask)
            for i in range(1, num_features + 1):
                component = labeled == i
                if np.sum(component) == 1:
                    mask[component] = False
                    
        else:
            # Dla maych region贸w - praktycznie bez czyszczenia
            # Tylko wypenij pojedyncze dziury
            mask = ndimage.binary_fill_holes(mask)
        
        return mask
        
    except Exception as e:
        print(f"Bd w preserve_detail_processing_ultra: {e}")
        return mask

def preserve_detail_processing(mask, initial_pixels):
    """Przetwarzanie z zachowaniem szczeg贸贸w i usuwaniem artefakt贸w"""
    try:
        from scipy import ndimage
        
        # Zaawansowane czyszczenie z zachowaniem szczeg贸贸w
        if initial_pixels > 2000:
            # Dla wikszych region贸w - bardziej agresywne czyszczenie
            structure = np.ones((3, 3))
            
            # 1. Zamknij mae dziury
            mask = ndimage.binary_closing(mask, structure=structure, iterations=2)
            
            # 2. Usu szum punktowy
            mask = ndimage.binary_opening(mask, structure=structure, iterations=1)
            
            # 3. Inteligentne usuwanie maych komponent贸w
            labeled, num_features = ndimage.label(mask)
            component_sizes = []
            
            for i in range(1, num_features + 1):
                size = np.sum(labeled == i)
                component_sizes.append(size)
            
            if component_sizes:
                # Usu komponenty mniejsze ni偶 0.5% najwikszego komponentu
                max_component_size = max(component_sizes)
                min_size = max(5, max_component_size * 0.005, initial_pixels // 500)
                
                for i in range(1, num_features + 1):
                    if component_sizes[i-1] < min_size:
                        mask[labeled == i] = False
                        
        elif initial_pixels > 500:
            # Dla rednich region贸w - umiarkowane czyszczenie
            structure = np.ones((3, 3))
            
            # Usu pojedyncze piksele i mae skupiska
            mask = ndimage.binary_opening(mask, structure=structure, iterations=1)
            
            labeled, num_features = ndimage.label(mask)
            min_size = max(3, initial_pixels // 200)
            
            for i in range(1, num_features + 1):
                if np.sum(labeled == i) < min_size:
                    mask[labeled == i] = False
                    
        else:
            # Dla maych region贸w - bardzo delikatne czyszczenie
            # Usu tylko pojedyncze izolowane piksele
            labeled, num_features = ndimage.label(mask)
            for i in range(1, num_features + 1):
                component = labeled == i
                if np.sum(component) <= 2:  # Usu tylko bardzo mae artefakty
                    # Sprawd藕 czy to rzeczywicie artefakt (izolowany)
                    dilated = ndimage.binary_dilation(component, iterations=2)
                    overlap = np.sum(dilated & (mask & ~component))
                    if overlap < 3:  # Bardzo mao pocze z reszt
                        mask[component] = False
        
        # Kocowe wypenienie maych dziur
        mask = ndimage.binary_fill_holes(mask)
        
        return mask
        
    except Exception as e:
        print(f"Bd w preserve_detail_processing: {e}")
        return mask

def smart_shape_preserving_merge(mask, img_array, color):
    """Inteligentne czenie z zachowaniem ksztat贸w"""
    try:
        from scipy import ndimage
        
        # Znajd藕 komponenty
        labeled, num_features = ndimage.label(mask)
        
        if num_features <= 1:
            return mask
        
        # Analizuj ka偶dy komponent
        color_array = np.array(color)
        merged_mask = np.zeros_like(mask)
        
        for i in range(1, num_features + 1):
            component = labeled == i
            component_size = np.sum(component)
            
            # Zachowaj wszystkie komponenty powy偶ej minimalnego rozmiaru
            if component_size >= 1:  # DRASTYCZNIE zmniejszony pr贸g - zachowaj ka偶dy piksel
                # Sprawd藕 jako dopasowania koloru
                component_pixels = img_array[component]
                if len(component_pixels) > 0:
                    mean_distance = np.mean(np.sqrt(np.sum((component_pixels - color_array)**2, axis=1)))
                    
                    # Bardzo liberalne kryteria dla zachowania szczeg贸贸w
                    if mean_distance <= 80:  # Jeszcze wy偶szy pr贸g tolerancji
                        merged_mask[component] = True
        
        return merged_mask
        
    except Exception as e:
        print(f"Bd w smart_shape_preserving_merge: {e}")
        return mask

def create_multi_method_mask(img_array, color, segments):
    """Tworzy mask u偶ywajc wielu metod"""
    try:
        height, width = img_array.shape[:2]
        color_array = np.array(color)
        
        # Metoda 1: Odlego RGB z adaptacyjnym progiem
        rgb_diff = np.sqrt(np.sum((img_array - color_array)**2, axis=2))
        brightness = np.mean(color)
        
        # Adaptacyjny pr贸g w zale偶noci od jasnoci i kontekstu
        if brightness < 40:
            threshold = 25
        elif brightness < 100:
            threshold = 30
        elif brightness > 200:
            threshold = 40
        else:
            threshold = 35
        
        mask1 = rgb_diff <= threshold
        
        # Metoda 2: Odlego w przestrzeni HSV
        try:
            hsv_img = rgb_to_hsv_manual(img_array)
            hsv_color = rgb_to_hsv_manual(color_array.reshape(1, 1, 3))[0, 0]
            hsv_diff = np.sqrt(np.sum((hsv_img - hsv_color)**2, axis=2))
            mask2 = hsv_diff <= threshold * 0.8
        except:
            mask2 = mask1
        
        # Metoda 3: Segmentacja
        mask3 = np.zeros((height, width), dtype=bool)
        if segments is not None:
            try:
                # Znajd藕 segmenty zawierajce podobne kolory
                for seg_id in np.unique(segments):
                    seg_mask = segments == seg_id
                    if np.sum(seg_mask) > 0:
                        seg_mean_color = np.mean(img_array[seg_mask], axis=0)
                        color_distance = np.sqrt(np.sum((seg_mean_color - color_array)**2))
                        if color_distance <= threshold:
                            mask3[seg_mask] = True
            except:
                pass
        
        # Kombinuj maski inteligentnie
        if np.sum(mask3) > 0:
            # Jeli segmentacja daa rezultaty, u偶yj jej jako bazy
            combined_mask = mask3 | (mask1 & mask2)
        else:
            # Inaczej kombinuj RGB i HSV
            combined_mask = mask1 | mask2
        
        return combined_mask if np.sum(combined_mask) > 0 else None
        
    except Exception as e:
        print(f"Bd w multi-method mask: {e}")
        return None

def rgb_to_hsv_manual(rgb):
    """Prosta konwersja RGB do HSV"""
    try:
        rgb = rgb.astype(float) / 255.0
        max_val = np.max(rgb, axis=2)
        min_val = np.min(rgb, axis=2)
        diff = max_val - min_val
        
        # Value
        v = max_val
        
        # Saturation
        s = np.where(max_val != 0, diff / max_val, 0)
        
        # Hue (uproszczona)
        h = np.zeros_like(max_val)
        
        return np.stack([h, s, v], axis=2)
    except:
        return rgb

def advanced_morphological_processing(mask, initial_pixels):
    """Zaawansowane przetwarzanie morfologiczne"""
    try:
        from scipy import ndimage
        
        # Adaptacyjne struktury w zale偶noci od rozmiaru regionu
        if initial_pixels > 5000:
            # Du偶e regiony - agresywne czyszczenie
            structure = np.ones((5, 5))
            mask = ndimage.binary_closing(mask, structure=structure, iterations=2)
            mask = ndimage.binary_opening(mask, structure=structure, iterations=1)
        elif initial_pixels > 1000:
            # rednie regiony - umiarkowane czyszczenie  
            structure = np.ones((3, 3))
            mask = ndimage.binary_closing(mask, structure=structure, iterations=2)
            mask = ndimage.binary_opening(mask, structure=structure, iterations=1)
        else:
            # Mae regiony - delikatne czyszczenie
            structure = np.ones((3, 3))
            mask = ndimage.binary_closing(mask, structure=structure, iterations=1)
        
        # Wypenij dziury
        mask = ndimage.binary_fill_holes(mask)
        
        # Usu bardzo mae komponenty
        labeled, num_features = ndimage.label(mask)
        min_size = max(5, initial_pixels // 50)
        
        for i in range(1, num_features + 1):
            if np.sum(labeled == i) < min_size:
                mask[labeled == i] = False
        
        return mask
        
    except Exception as e:
        print(f"Bd w morphological processing: {e}")
        return mask

def intelligent_fragment_merging(mask, img_array, color):
    """Inteligentne czenie fragment贸w o podobnych kolorach"""
    try:
        from scipy import ndimage
        
        # Znajd藕 komponenty
        labeled, num_features = ndimage.label(mask)
        
        if num_features <= 1:
            return mask
        
        # Sprawd藕 czy komponenty mo偶na poczy
        color_array = np.array(color)
        merged_mask = np.zeros_like(mask)
        
        for i in range(1, num_features + 1):
            component = labeled == i
            component_pixels = img_array[component]
            
            if len(component_pixels) > 0:
                # Sprawd藕 redni kolor komponentu
                mean_color = np.mean(component_pixels, axis=0)
                color_distance = np.sqrt(np.sum((mean_color - color_array)**2))
                
                # Jeli kolor jest podobny, dodaj do wyniku
                if color_distance <= 50:  # Liberalny pr贸g dla czenia
                    merged_mask[component] = True
        
        return merged_mask
        
    except Exception as e:
        print(f"Bd w fragment merging: {e}")
        return mask

def create_color_regions_simple(image, colors):
    """Prosta metoda tworzenia region贸w kolor贸w"""
    try:
        width, height = image.size
        img_array = np.array(image)
        
        regions = []
        
        for color in colors:
            print(f"Prosta metoda - przetwarzanie koloru: {color}")
            
            # Zwikszona tolerancja dla prostej metody
            tolerance = 60
            
            # Wektoryzowana operacja zamiast ptli
            color_array = np.array(color)
            diff = np.abs(img_array - color_array)
            mask = np.all(diff <= tolerance, axis=2)
            
            pixel_count = np.sum(mask)
            print(f"Prosta metoda - piksele dla koloru {color}: {pixel_count}")
            
            if pixel_count > 10:  # Bardzo liberalny pr贸g
                regions.append((color, mask))
                print(f" Prosta metoda - dodano region dla koloru {color}")
        
        print(f"Prosta metoda - utworzono {len(regions)} region贸w")
        return regions
        
    except Exception as e:
        print(f"Bd podczas prostego tworzenia region贸w: {e}")
        return []

def trace_contours_advanced(mask):
    """Ultra precyzyjne ledzenie kontur贸w z zachowaniem detali oryginalnego ksztatu"""
    try:
        from scipy import ndimage
        
        # Analiza maski dla wyboru optymalnej strategii
        mask_size = np.sum(mask)
        mask_complexity = analyze_mask_complexity(mask)
        
        print(f"   Analiza maski: rozmiar={mask_size}, zo偶ono={mask_complexity}")
        
        # Minimalne przetwarzanie wstpne - zachowaj oryginalny ksztat
        processed_mask = minimal_mask_preprocessing(mask)
        
        # Wyb贸r metody ledzenia bazujcej na rozmiarze i zo偶onoci
        if mask_size > 1000 and mask_complexity == 'high':
            contours = trace_high_detail_contours(processed_mask)
        elif mask_complexity == 'medium':
            contours = trace_balanced_contours(processed_mask)
        else:
            contours = trace_simple_precise_contours(processed_mask)
        
        # Minimalna post-processing - zachowaj szczeg贸y
        final_contours = []
        for contour in contours:
            if len(contour) >= 3:
                # Bardzo delikatna optymalizacja
                optimized = minimal_contour_optimization(contour)
                if optimized and len(optimized) >= 3:
                    final_contours.append(optimized)
        
        print(f"   Wygenerowano {len(final_contours)} kontur贸w ultra wysokiej precyzji")
        return final_contours
        
    except Exception as e:
        print(f" Bd podczas ultra precyzyjnego ledzenia: {e}")
        return trace_contours_simple_improved(mask)

def analyze_mask_complexity(mask):
    """Analizuje zo偶ono ksztatu maski"""
    try:
        from scipy import ndimage
        
        # Policz komponenty
        labeled, num_features = ndimage.label(mask)
        
        # Policz "dziury" (holes)
        filled = ndimage.binary_fill_holes(mask)
        holes = filled & ~mask
        num_holes = np.sum(holes)
        
        # Policz zmienno krawdzi
        edges = ndimage.sobel(mask.astype(float))
        edge_variance = np.var(edges[edges > 0]) if np.any(edges > 0) else 0
        
        # Klasyfikacja zo偶onoci
        if num_features > 3 or num_holes > 10 or edge_variance > 0.5:
            return 'high'
        elif num_features > 1 or num_holes > 2 or edge_variance > 0.2:
            return 'medium'
        else:
            return 'simple'
    except:
        return 'medium'

def minimal_mask_preprocessing(mask):
    """Minimalne przetwarzanie maski - zachowaj oryginalny ksztat"""
    try:
        from scipy import ndimage
        
        # Tylko usu pojedyncze izolowane piksele
        labeled, num_features = ndimage.label(mask)
        cleaned_mask = mask.copy()
        
        for i in range(1, num_features + 1):
            component = labeled == i
            if np.sum(component) == 1:  # Pojedynczy piksel
                cleaned_mask[component] = False
        
        return cleaned_mask
    except:
        return mask

def trace_high_detail_contours(mask):
    """ledzenie kontur贸w dla wysokich detali"""
    try:
        if cv2 is not None:
            mask_uint8 = (mask * 255).astype(np.uint8)
            
            # U偶yj CHAIN_APPROX_NONE dla zachowania wszystkich punkt贸w
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
            
            processed = []
            for contour in contours:
                if len(contour) >= 6:
                    # Minimalne upraszczanie - zachowaj 95% punkt贸w
                    perimeter = cv2.arcLength(contour, True)
                    epsilon = 0.001 * perimeter  # Bardzo may epsilon
                    simplified = cv2.approxPolyDP(contour, epsilon, True)
                    
                    if len(simplified) >= 3:
                        points = [(int(p[0][0]), int(p[0][1])) for p in simplified]
                        processed.append(points)
            
            return processed
        else:
            return trace_contours_simple_improved(mask)
    except:
        return trace_contours_simple_improved(mask)

def trace_balanced_contours(mask):
    """ledzenie kontur贸w z balansem midzy precyzj a wydajnoci"""
    try:
        if cv2 is not None:
            mask_uint8 = (mask * 255).astype(np.uint8)
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            processed = []
            for contour in contours:
                if len(contour) >= 4:
                    perimeter = cv2.arcLength(contour, True)
                    epsilon = 0.002 * perimeter  # Umiarkowane upraszczanie
                    simplified = cv2.approxPolyDP(contour, epsilon, True)
                    
                    if len(simplified) >= 3:
                        points = [(int(p[0][0]), int(p[0][1])) for p in simplified]
                        processed.append(points)
            
            return processed
        else:
            return trace_contours_simple_improved(mask)
    except:
        return trace_contours_simple_improved(mask)

def trace_simple_precise_contours(mask):
    """ledzenie kontur贸w dla prostych ksztat贸w z wysok precyzj"""
    try:
        if cv2 is not None:
            mask_uint8 = (mask * 255).astype(np.uint8)
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1)
            
            processed = []
            for contour in contours:
                if len(contour) >= 3:
                    # Bardzo delikatne upraszczanie
                    perimeter = cv2.arcLength(contour, True)
                    epsilon = 0.0005 * perimeter  # Minimalny epsilon
                    simplified = cv2.approxPolyDP(contour, epsilon, True)
                    
                    if len(simplified) >= 3:
                        points = [(int(p[0][0]), int(p[0][1])) for p in simplified]
                        processed.append(points)
            
            return processed
        else:
            return trace_contours_simple_improved(mask)
    except:
        return trace_contours_simple_improved(mask)

def minimal_contour_optimization(contour):
    """Minimalna optymalizacja konturu - zachowaj maksimum szczeg贸贸w"""
    try:
        if len(contour) <= 5:
            return contour
        
        # Usu tylko punkty, kt贸re s bardzo blisko siebie
        optimized = [contour[0]]
        
        for i in range(1, len(contour)):
            current = contour[i]
            last = optimized[-1]
            
            # Usu tylko jeli punkty s praktycznie identyczne
            distance = np.sqrt((current[0] - last[0])**2 + (current[1] - last[1])**2)
            if distance >= 1.0:  # Bardzo niski pr贸g
                optimized.append(current)
        
        return optimized if len(optimized) >= 3 else contour
    except:
        return contour

def analyze_mask_shape(mask):
    """Analizuje typ ksztatu maski"""
    try:
        from scipy import ndimage
        
        # Oblicz wska藕niki geometryczne
        labeled, num_features = ndimage.label(mask)
        
        if num_features == 0:
            return 'empty'
        
        # Dla najwikszego komponentu
        largest_component = labeled == np.bincount(labeled.flat)[1:].argmax() + 1
        
        # Wypenienie vs. obw贸d
        area = np.sum(largest_component)
        
        # Znajd藕 obw贸d
        try:
            if cv2 is not None:
                mask_uint8 = (largest_component * 255).astype(np.uint8)
                contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                if contours:
                    perimeter = cv2.arcLength(contours[0], True)
                else:
                    perimeter = 0
            else:
                # Aproksymacja obwodu bez OpenCV
                edges = ndimage.sobel(largest_component.astype(float))
                perimeter = np.sum(edges > 0)
        except:
            perimeter = np.sqrt(area) * 4  # Aproksymacja
        
        # Wska藕nik ksztatu (4 * pole / obw贸d虏)
        if perimeter > 0:
            shape_factor = (4 * np.pi * area) / (perimeter ** 2)
        else:
            shape_factor = 0
        
        # Klasyfikacja
        if shape_factor > 0.7:  # Prawie koo
            return 'geometric'
        elif shape_factor > 0.3:  # Umiarkowanie regularne
            return 'mixed'
        else:  # Nieregularne
            return 'organic'
            
    except:
        return 'mixed'

def preserve_sharp_edges(mask):
    """Zachowuje ostre krawdzie dla geometrycznych ksztat贸w"""
    try:
        from scipy import ndimage
        
        # Minimalne wygadzanie
        smoothed = ndimage.gaussian_filter(mask.astype(float), sigma=0.3) > 0.7
        
        # Zachowaj oryginalne krawdzie tam gdzie to mo偶liwe
        edges = ndimage.sobel(mask.astype(float)) > 0.1
        result = smoothed.copy()
        result[edges] = mask[edges]
        
        return result
    except:
        return mask

def smooth_organic_edges(mask):
    """Wygadza krawdzie dla organicznych ksztat贸w"""
    try:
        from scipy import ndimage
        
        # Wiksze wygadzanie dla organicznych ksztat贸w
        smoothed = ndimage.gaussian_filter(mask.astype(float), sigma=1.0) > 0.4
        
        # Wypenij mae dziury
        filled = ndimage.binary_fill_holes(smoothed)
        
        # Delikatne morfologiczne czyszczenie
        structure = np.ones((3, 3))
        cleaned = ndimage.binary_opening(filled, structure=structure)
        
        return cleaned
    except:
        return mask

def hybrid_processing(mask):
    """Hybrydowe przetwarzanie dla mieszanych ksztat贸w"""
    try:
        from scipy import ndimage
        
        # Umiarkowane wygadzanie
        smoothed = ndimage.gaussian_filter(mask.astype(float), sigma=0.6) > 0.5
        
        # Adaptacyjne morfologiczne przetwarzanie
        structure_small = np.ones((3, 3))
        cleaned = ndimage.binary_closing(smoothed, structure=structure_small)
        cleaned = ndimage.binary_fill_holes(cleaned)
        
        return cleaned
    except:
        return mask

def trace_geometric_contours(mask):
    """ledzenie kontur贸w dla geometrycznych ksztat贸w"""
    try:
        if cv2 is not None:
            mask_uint8 = (mask * 255).astype(np.uint8)
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            processed = []
            for contour in contours:
                if len(contour) >= 4:
                    # Minimalne upraszczanie dla zachowania ksztatu
                    perimeter = cv2.arcLength(contour, True)
                    epsilon = 0.002 * perimeter  # Bardzo may epsilon
                    simplified = cv2.approxPolyDP(contour, epsilon, True)
                    
                    if len(simplified) >= 3:
                        points = [(int(p[0][0]), int(p[0][1])) for p in simplified]
                        processed.append(points)
            
            return processed
        else:
            return trace_contours_simple_improved(mask)
    except:
        return trace_contours_simple_improved(mask)

def trace_organic_contours(mask):
    """ledzenie kontur贸w dla organicznych ksztat贸w"""
    try:
        if cv2 is not None:
            mask_uint8 = (mask * 255).astype(np.uint8)
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_KCOS)
            
            processed = []
            for contour in contours:
                if len(contour) >= 6:
                    # Wiksze upraszczanie dla organicznych ksztat贸w
                    perimeter = cv2.arcLength(contour, True)
                    epsilon = 0.01 * perimeter
                    simplified = cv2.approxPolyDP(contour, epsilon, True)
                    
                    if len(simplified) >= 3:
                        points = [(int(p[0][0]), int(p[0][1])) for p in simplified]
                        # Wygadzanie dla organicznych ksztat贸w
                        smoothed = smooth_contour_points(points)
                        processed.append(smoothed)
            
            return processed
        else:
            return trace_contours_simple_improved(mask)
    except:
        return trace_contours_simple_improved(mask)

def trace_hybrid_contours(mask):
    """ledzenie kontur贸w dla mieszanych ksztat贸w"""
    try:
        if cv2 is not None:
            mask_uint8 = (mask * 255).astype(np.uint8)
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            processed = []
            for contour in contours:
                if len(contour) >= 4:
                    perimeter = cv2.arcLength(contour, True)
                    epsilon = 0.005 * perimeter  # Umiarkowane upraszczanie
                    simplified = cv2.approxPolyDP(contour, epsilon, True)
                    
                    if len(simplified) >= 3:
                        points = [(int(p[0][0]), int(p[0][1])) for p in simplified]
                        processed.append(points)
            
            return processed
        else:
            return trace_contours_simple_improved(mask)
    except:
        return trace_contours_simple_improved(mask)

def optimize_contour_points(contour, shape_type):
    """Optymalizuje punkty konturu w zale偶noci od typu ksztatu"""
    try:
        if len(contour) < 3:
            return contour
        
        if shape_type == 'geometric':
            # Dla geometrycznych - usu zbdne punkty na prostych
            return remove_collinear_points(contour)
        elif shape_type == 'organic':
            # Dla organicznych - delikatne wygadzanie
            return smooth_contour_points(contour)
        else:
            # Dla mieszanych - minimalna optymalizacja
            return reduce_redundant_points(contour)
            
    except:
        return contour

def remove_collinear_points(points, tolerance=2.0):
    """Usuwa punkty le偶ce na prostej"""
    if len(points) <= 3:
        return points
    
    filtered = [points[0]]
    
    for i in range(1, len(points) - 1):
        p1 = np.array(filtered[-1])
        p2 = np.array(points[i])
        p3 = np.array(points[i + 1])
        
        # Oblicz odlego punktu od prostej
        line_vec = p3 - p1
        point_vec = p2 - p1
        
        if np.linalg.norm(line_vec) > 0:
            # Odlego punktu od prostej
            cross = np.cross(point_vec, line_vec)
            distance = abs(cross) / np.linalg.norm(line_vec)
            
            if distance > tolerance:
                filtered.append(points[i])
    
    filtered.append(points[-1])
    return filtered

def smooth_contour_points(points, factor=0.3):
    """Wygadza punkty konturu"""
    if len(points) <= 3:
        return points
    
    smoothed = []
    for i in range(len(points)):
        prev_idx = (i - 1) % len(points)
        next_idx = (i + 1) % len(points)
        
        current = np.array(points[i])
        prev_point = np.array(points[prev_idx])
        next_point = np.array(points[next_idx])
        
        # Wygadzanie
        smooth_point = current * (1 - factor) + (prev_point + next_point) * factor / 2
        smoothed.append((int(smooth_point[0]), int(smooth_point[1])))
    
    return smoothed

def reduce_redundant_points(points, min_distance=3):
    """Usuwa zbdnie blisko poo偶one punkty"""
    if len(points) <= 3:
        return points
    
    filtered = [points[0]]
    
    for point in points[1:]:
        last_point = filtered[-1]
        distance = np.sqrt((point[0] - last_point[0])**2 + (point[1] - last_point[1])**2)
        
        if distance >= min_distance:
            filtered.append(point)
    
    return filtered

def trace_contours_simple_improved(mask):
    """Ulepszona prosta metoda ledzenia kontur贸w"""
    try:
        from skimage import measure
        
        # U偶yj skimage do znajdowania kontur贸w
        contours = measure.find_contours(mask, 0.5)
        
        processed_contours = []
        for contour in contours:
            if len(contour) >= 6:
                # Zmie kolejno wsp贸rzdnych (y,x) -> (x,y)
                points = [(int(point[1]), int(point[0])) for point in contour[::2]]  # Co drugi punkt
                
                if len(points) >= 4:
                    processed_contours.append(points)
        
        return processed_contours
    except:
        # Ostateczny fallback
        return trace_contours_simple(mask)

def trace_contours_simple(mask):
    """Proste ledzenie kontur贸w"""
    try:
        height, width = mask.shape
        contours = []
        
        # Znajd藕 punkty brzegowe
        edge_points = []
        for y in range(1, height - 1):
            for x in range(1, width - 1):
                if mask[y, x]:
                    # Sprawd藕 czy to punkt brzegowy
                    neighbors = [
                        mask[y-1, x-1], mask[y-1, x], mask[y-1, x+1],
                        mask[y, x-1], mask[y, x+1],
                        mask[y+1, x-1], mask[y+1, x], mask[y+1, x+1]
                    ]
                    if not all(neighbors):
                        edge_points.append((x, y))
        
        if len(edge_points) >= 3:
            # Ogranicz liczb punkt贸w
            if len(edge_points) > 100:
                step = len(edge_points) // 50
                edge_points = edge_points[::step]
            
            contours.append(edge_points)
        
        return contours
    except Exception as e:
        print(f"Bd podczas prostego ledzenia kontur贸w: {e}")
        return []

def create_smooth_svg_path(contour):
    """Tworzy ultra precyzyjn cie偶k SVG z zachowaniem szczeg贸贸w oryginalnego ksztatu"""
    if len(contour) < 3:
        return None
    
    try:
        # Minimalna analiza - zachowaj oryginalny ksztat
        contour_detail_level = analyze_contour_detail_level(contour)
        
        # Bardzo minimalne upraszczanie - zachowaj wikszo punkt贸w
        preserved_contour = preserve_contour_details(contour, contour_detail_level)
        
        print(f"     Kontur: {len(contour)}  {len(preserved_contour)} punkt贸w, szczeg贸owo: {contour_detail_level}")
        
        # Wybierz metod zachowujc szczeg贸y
        if contour_detail_level == 'high':
            path_data = create_high_fidelity_svg_path(preserved_contour)
        elif contour_detail_level == 'medium':
            path_data = create_balanced_svg_path(preserved_contour)
        else:
            path_data = create_simple_accurate_svg_path(preserved_contour)
        
        return path_data
        
    except Exception as e:
        print(f"Bd podczas tworzenia precyzyjnej cie偶ki SVG: {e}")
        return create_simple_svg_path(contour)

def analyze_contour_detail_level(contour):
    """Analizuje poziom szczeg贸owoci konturu"""
    try:
        if len(contour) > 50:
            return 'high'
        elif len(contour) > 20:
            return 'medium'
        else:
            return 'simple'
    except:
        return 'medium'

def preserve_contour_details(contour, detail_level):
    """Zachowuje szczeg贸y konturu z minimalnym upraszczaniem"""
    try:
        if detail_level == 'high':
            # Zachowaj 95% punkt贸w
            step = max(1, len(contour) // 95)
        elif detail_level == 'medium':
            # Zachowaj 90% punkt贸w
            step = max(1, len(contour) // 45)
        else:
            # Zachowaj wikszo punkt贸w
            step = max(1, len(contour) // 20)
        
        if step == 1:
            return contour
        else:
            preserved = contour[::step]
            # Zawsze zachowaj pierwszy i ostatni punkt
            if len(preserved) > 0 and preserved[-1] != contour[-1]:
                preserved.append(contour[-1])
            return preserved
    except:
        return contour

def create_high_fidelity_svg_path(contour):
    """Tworzy cie偶k SVG wysokiej wiernoci"""
    try:
        if len(contour) < 3:
            return create_simple_svg_path(contour)
        
        path_data = f"M {contour[0][0]:.3f} {contour[0][1]:.3f}"
        
        # U偶yj krzywych dla pynnych przej, ale zachowaj precyzj
        i = 1
        while i < len(contour):
            if i + 2 < len(contour):
                # Sprawd藕 czy warto u偶y krzywej
                if should_use_curve_precise(contour, i):
                    p1 = contour[i]
                    p2 = contour[i + 1]
                    
                    # Delikatne krzywe Beziera
                    cp1_x = p1[0] + (p2[0] - contour[i-1][0]) * 0.15
                    cp1_y = p1[1] + (p2[1] - contour[i-1][1]) * 0.15
                    
                    path_data += f" Q {cp1_x:.3f} {cp1_y:.3f} {p2[0]:.3f} {p2[1]:.3f}"
                    i += 2
                else:
                    current = contour[i]
                    path_data += f" L {current[0]:.3f} {current[1]:.3f}"
                    i += 1
            else:
                current = contour[i]
                path_data += f" L {current[0]:.3f} {current[1]:.3f}"
                i += 1
        
        path_data += " Z"
        return path_data
    except:
        return create_simple_svg_path(contour)

def create_balanced_svg_path(contour):
    """Tworzy zbalansowan cie偶k SVG"""
    try:
        path_data = f"M {contour[0][0]:.2f} {contour[0][1]:.2f}"
        
        for i in range(1, len(contour)):
            current = contour[i]
            
            # U偶ywaj g贸wnie linii z okazjonalnymi krzywymi
            if i % 3 == 0 and i + 1 < len(contour) and should_use_curve_precise(contour, i):
                next_point = contour[i + 1] if i + 1 < len(contour) else contour[0]
                prev_point = contour[i - 1]
                
                cp_x = current[0] + (next_point[0] - prev_point[0]) * 0.1
                cp_y = current[1] + (next_point[1] - prev_point[1]) * 0.1
                
                path_data += f" Q {cp_x:.2f} {cp_y:.2f} {current[0]:.2f} {current[1]:.2f}"
            else:
                path_data += f" L {current[0]:.2f} {current[1]:.2f}"
        
        path_data += " Z"
        return path_data
    except:
        return create_simple_svg_path(contour)

def create_simple_accurate_svg_path(contour):
    """Tworzy prost ale dokadn cie偶k SVG"""
    try:
        path_data = f"M {contour[0][0]:.2f} {contour[0][1]:.2f}"
        
        for point in contour[1:]:
            path_data += f" L {point[0]:.2f} {point[1]:.2f}"
        
        path_data += " Z"
        return path_data
    except:
        return create_simple_svg_path(contour)

def should_use_curve_precise(contour, index):
    """Precyzyjnie okrela czy u偶y krzywej"""
    try:
        if index < 1 or index >= len(contour) - 1:
            return False
        
        prev_point = contour[index - 1]
        current = contour[index]
        next_point = contour[index + 1]
        
        # Oblicz kty midzy segmentami
        v1 = (current[0] - prev_point[0], current[1] - prev_point[1])
        v2 = (next_point[0] - current[0], next_point[1] - current[1])
        
        len1 = np.sqrt(v1[0]**2 + v1[1]**2)
        len2 = np.sqrt(v2[0]**2 + v2[1]**2)
        
        if len1 == 0 or len2 == 0:
            return False
        
        # Znormalizuj wektory
        v1_norm = (v1[0]/len1, v1[1]/len1)
        v2_norm = (v2[0]/len2, v2[1]/len2)
        
        # Oblicz kt
        dot_product = v1_norm[0] * v2_norm[0] + v1_norm[1] * v2_norm[1]
        angle = np.arccos(np.clip(dot_product, -1, 1))
        
        # U偶yj krzywej dla agodnych zakrt贸w i odpowiednio dugich segment贸w
        return angle > np.pi/6 and min(len1, len2) > 8
    except:
        return False

def analyze_contour_characteristics(contour):
    """Analizuje charakterystyk konturu"""
    try:
        if len(contour) < 4:
            return {'type': 'simple', 'complexity': 'low', 'smoothness': 'high'}
        
        # Oblicz kty midzy kolejnymi segmentami
        angles = []
        for i in range(len(contour)):
            p1 = contour[i]
            p2 = contour[(i + 1) % len(contour)]
            p3 = contour[(i + 2) % len(contour)]
            
            v1 = (p2[0] - p1[0], p2[1] - p1[1])
            v2 = (p3[0] - p2[0], p3[1] - p2[1])
            
            # Oblicz kt
            try:
                angle = np.arccos(np.clip(
                    (v1[0]*v2[0] + v1[1]*v2[1]) / 
                    (np.sqrt(v1[0]**2 + v1[1]**2) * np.sqrt(v2[0]**2 + v2[1]**2)),
                    -1, 1
                ))
                angles.append(angle)
            except:
                angles.append(np.pi)
        
        # Analiza kt贸w
        sharp_angles = sum(1 for a in angles if a < np.pi/3)  # Ostre kty
        smooth_angles = sum(1 for a in angles if a > 2*np.pi/3)  # Pynne kty
        
        # Dugoci segment贸w
        segment_lengths = []
        for i in range(len(contour)):
            p1 = contour[i]
            p2 = contour[(i + 1) % len(contour)]
            length = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)
            segment_lengths.append(length)
        
        avg_length = np.mean(segment_lengths)
        length_variance = np.var(segment_lengths)
        
        # Klasyfikacja
        if sharp_angles > len(contour) * 0.6:
            contour_type = 'geometric'
        elif smooth_angles > len(contour) * 0.6:
            contour_type = 'organic'
        else:
            contour_type = 'hybrid'
        
        complexity = 'high' if len(contour) > 50 else 'medium' if len(contour) > 20 else 'low'
        smoothness = 'low' if length_variance > avg_length**2 else 'medium' if length_variance > avg_length/2 else 'high'
        
        return {
            'type': contour_type,
            'complexity': complexity,
            'smoothness': smoothness,
            'sharp_angles': sharp_angles,
            'smooth_angles': smooth_angles,
            'avg_segment_length': avg_length
        }
        
    except Exception as e:
        print(f"Bd w analizie konturu: {e}")
        return {'type': 'hybrid', 'complexity': 'medium', 'smoothness': 'medium'}

def adaptive_contour_simplification(contour, analysis):
    """Adaptacyjne upraszczanie konturu"""
    try:
        if analysis['complexity'] == 'low':
            # Niski poziom upraszczania dla prostych ksztat贸w
            return contour[::max(1, len(contour) // 20)]
        elif analysis['complexity'] == 'medium':
            # redni poziom upraszczania
            return contour[::max(1, len(contour) // 35)]
        else:
            # Wysokie zachowanie detali dla zo偶onych ksztat贸w
            return contour[::max(1, len(contour) // 60)]
    except:
        return contour

def create_geometric_svg_path(contour):
    """Tworzy cie偶k SVG dla geometrycznych ksztat贸w"""
    try:
        path_data = f"M {contour[0][0]:.2f} {contour[0][1]:.2f}"
        
        # U偶ywaj g贸wnie linii prostych z okazjonalnymi krzywymi
        for i in range(1, len(contour)):
            current = contour[i]
            path_data += f" L {current[0]:.2f} {current[1]:.2f}"
        
        path_data += " Z"
        return path_data
    except:
        return create_simple_svg_path(contour)

def create_organic_svg_path(contour):
    """Tworzy cie偶k SVG dla organicznych ksztat贸w"""
    try:
        if len(contour) < 4:
            return create_simple_svg_path(contour)
        
        path_data = f"M {contour[0][0]:.2f} {contour[0][1]:.2f}"
        
        # U偶ywaj krzywych Beziera dla pynnych ksztat贸w
        i = 1
        while i < len(contour):
            if i + 2 < len(contour):
                # Krzywa kubiczna Beziera
                p1 = contour[i]
                p2 = contour[i + 1]
                p3 = contour[i + 2]
                
                # Oblicz punkty kontrolne
                cp1_x = p1[0] + (p2[0] - contour[i-1][0]) * 0.3
                cp1_y = p1[1] + (p2[1] - contour[i-1][1]) * 0.3
                
                cp2_x = p2[0] - (p3[0] - p1[0]) * 0.3
                cp2_y = p2[1] - (p3[1] - p1[1]) * 0.3
                
                path_data += f" C {cp1_x:.2f} {cp1_y:.2f} {cp2_x:.2f} {cp2_y:.2f} {p2[0]:.2f} {p2[1]:.2f}"
                i += 1
            else:
                # Linia prosta dla pozostaych punkt贸w
                current = contour[i]
                path_data += f" L {current[0]:.2f} {current[1]:.2f}"
                i += 1
        
        path_data += " Z"
        return path_data
    except:
        return create_simple_svg_path(contour)

def create_hybrid_svg_path(contour):
    """Tworzy cie偶k SVG dla mieszanych ksztat贸w"""
    try:
        if len(contour) < 4:
            return create_simple_svg_path(contour)
        
        path_data = f"M {contour[0][0]:.2f} {contour[0][1]:.2f}"
        
        # Inteligentnie wybieraj midzy liniami a krzywymi
        i = 1
        while i < len(contour):
            if i + 1 < len(contour):
                current = contour[i]
                next_point = contour[i + 1]
                
                # Sprawd藕 czy segment jest odpowiedni dla krzywej
                if should_use_curve(contour, i):
                    # U偶yj krzywej kwadratowej
                    prev_point = contour[i - 1] if i > 0 else contour[-1]
                    
                    cp_x = current[0] + (next_point[0] - prev_point[0]) * 0.2
                    cp_y = current[1] + (next_point[1] - prev_point[1]) * 0.2
                    
                    path_data += f" Q {cp_x:.2f} {cp_y:.2f} {next_point[0]:.2f} {next_point[1]:.2f}"
                    i += 2
                else:
                    # U偶yj linii prostej
                    path_data += f" L {current[0]:.2f} {current[1]:.2f}"
                    i += 1
            else:
                current = contour[i]
                path_data += f" L {current[0]:.2f} {current[1]:.2f}"
                i += 1
        
        path_data += " Z"
        return path_data
    except:
        return create_simple_svg_path(contour)

def should_use_curve(contour, index):
    """Okrela czy segment powinien u偶ywa krzywej"""
    try:
        if index < 1 or index >= len(contour) - 1:
            return False
        
        prev_point = contour[index - 1]
        current = contour[index]
        next_point = contour[index + 1]
        
        # Oblicz kt
        v1 = (current[0] - prev_point[0], current[1] - prev_point[1])
        v2 = (next_point[0] - current[0], next_point[1] - current[1])
        
        # Sprawd藕 dugoci segment贸w
        len1 = np.sqrt(v1[0]**2 + v1[1]**2)
        len2 = np.sqrt(v2[0]**2 + v2[1]**2)
        
        if len1 == 0 or len2 == 0:
            return False
        
        # Znormalizuj wektory
        v1_norm = (v1[0]/len1, v1[1]/len1)
        v2_norm = (v2[0]/len2, v2[1]/len2)
        
        # Oblicz kt midzy wektorami
        dot_product = v1_norm[0] * v2_norm[0] + v1_norm[1] * v2_norm[1]
        angle = np.arccos(np.clip(dot_product, -1, 1))
        
        # U偶ywaj krzywej jeli kt nie jest zbyt ostry i segmenty s odpowiednio dugie
        return angle > np.pi/4 and min(len1, len2) > 5
    except:
        return False

def create_simple_svg_path(contour):
    """Tworzy prost cie偶k SVG"""
    if len(contour) < 3:
        return None
    
    simplified = contour[::max(1, len(contour)//20)]  # Maksymalnie 20 punkt贸w
    
    path_data = f"M {simplified[0][0]} {simplified[0][1]}"
    for point in simplified[1:]:
        path_data += f" L {point[0]} {point[1]}"
    path_data += " Z"
    
    return path_data

def analyze_image_complexity(image):
    """Analizuje zo偶ono obrazu i dostosowuje parametry z maksymalnym priorytetem na szczeg贸owo"""
    try:
        img_array = np.array(image)
        
        # Oblicz wska藕niki zo偶onoci
        edge_density = detect_edge_density(img_array)
        color_complexity = detect_color_complexity(img_array)
        
        # Oblicz entropi obrazu
        from scipy.stats import entropy
        hist, _ = np.histogram(img_array.flatten(), bins=256, range=(0, 256))
        img_entropy = entropy(hist + 1e-10)  # Dodaj ma warto aby unikn log(0)
        
        print(f" Analiza zo偶onoci: krawdzie={edge_density:.3f}, kolory={color_complexity}, entropia={img_entropy:.3f}")
        
        # MAKSYMALNA SZCZEGOWO: Drastycznie zwikszone parametry dla wiernoci oryginaowi
        if edge_density > 0.08 and color_complexity > 100:
            return {
                'max_colors': 40,  # Drastycznie zwikszono dla maksymalnej szczeg贸owoci
                'tolerance_factor': 0.4,  # Bardzo wysoka precyzja
                'detail_preservation': 'ultra_maximum',
                'min_region_size': 1,  # Zachowaj ka偶dy piksel
                'color_flattening': False,  # Wycz spaszczanie dla zachowania wszystkich odcieni
                'quality_enhancement': 'ultra_maximum'
            }
        elif edge_density > 0.05 or color_complexity > 50:
            return {
                'max_colors': 32,  # Bardzo wysokie dla detali
                'tolerance_factor': 0.45,
                'detail_preservation': 'ultra_high',
                'min_region_size': 1,
                'color_flattening': False,
                'quality_enhancement': 'maximum'
            }
        elif color_complexity > 25:
            return {
                'max_colors': 28,  # Wysokie dla rednich obraz贸w
                'tolerance_factor': 0.5,
                'detail_preservation': 'very_high',
                'min_region_size': 1,
                'color_flattening': False,
                'quality_enhancement': 'high'
            }
        else:
            return {
                'max_colors': 24,  # Minimum dla prostych obraz贸w
                'tolerance_factor': 0.55,
                'detail_preservation': 'high',
                'min_region_size': 1,
                'color_flattening': False,
                'quality_enhancement': 'high'
            }
    except:
        return {
            'max_colors': 32,  # Domylnie wysokie dla szczeg贸owoci
            'tolerance_factor': 0.5,
            'detail_preservation': 'ultra_high',
            'min_region_size': 1,
            'color_flattening': False,
            'quality_enhancement': 'maximum'
        }

def vectorize_image_improved(image_path, output_path):
    """Rewolucyjna wektoryzacja z maksymaln jakoci i precyzj"""
    try:
        print(" Rozpoczynanie REWOLUCYJNEJ wektoryzacji z maksymaln jakoci...")
        
        # NOWA STRATEGIA: Wielopoziomowa analiza obrazu
        original_image = Image.open(image_path)
        
        # 1. Multi-scale analysis - analizuj obraz w r贸偶nych rozdzielczociach
        scales = [0.5, 1.0, 2.0]  # R贸偶ne skale dla lepszej analizy
        multi_scale_data = []
        
        for scale in scales:
            scaled_size = (int(original_image.width * scale), int(original_image.height * scale))
            if max(scaled_size) > 2000:  # Limit dla wydajnoci
                scale_factor = 2000 / max(scaled_size)
                scaled_size = (int(scaled_size[0] * scale_factor), int(scaled_size[1] * scale_factor))
            
            scaled_image = original_image.resize(scaled_size, Image.Resampling.LANCZOS)
            
            # Zaawansowane pre-processing dla ka偶dej skali
            processed_image = revolutionary_image_preprocessing(scaled_image, scale)
            multi_scale_data.append((scale, processed_image))
            print(f" Przeanalizowano skal {scale}x: {processed_image.size}")
        
        # 2. Wyb贸r optymalnej skali bazujc na analizie szczeg贸owoci
        best_scale, optimized_image = select_optimal_scale(multi_scale_data)
        print(f" Wybrano optymaln skal: {best_scale}x, rozmiar: {optimized_image.size}")
        
        # 3. NOWY ALGORYTM: Adaptacyjna analiza zo偶onoci z uczeniem maszynowym
        complexity_params = revolutionary_complexity_analysis(optimized_image)
        
        # 4. PRZEOMOWE wyciganie kolor贸w z technologi Deep Color Analysis
        max_colors = min(80, complexity_params['max_colors'])  # Drastycznie zwikszono limit
        
        # 5. REWOLUCYJNE podniesienie jakoci z AI-enhanced processing
        if complexity_params.get('quality_enhancement') == 'revolutionary':
            optimized_image = revolutionary_quality_enhancement(optimized_image)
            print(" Zastosowano REWOLUCYJNE podniesienie jakoci z AI")
        elif complexity_params.get('quality_enhancement') == 'ultra_maximum':
            optimized_image = enhance_image_quality_ultra_maximum(optimized_image)
            print(" Zastosowano ULTRA maksymalne podniesienie jakoci obrazu")
        elif complexity_params.get('quality_enhancement') == 'maximum':
            optimized_image = enhance_image_quality_maximum(optimized_image)
            print(" Zastosowano maksymalne podniesienie jakoci obrazu")
        
        # 6. PRZEOMOWA analiza kolor贸w z technologi Deep Learning
        colors = revolutionary_color_extraction(optimized_image, max_colors=max_colors*4, params=complexity_params)
        
        # Spaszczenie kolor贸w jeli wczone - dla maksymalnej szczeg贸owoci czsto wyczone
        if complexity_params.get('color_flattening', False):
            colors = flatten_color_palette(colors, target_count=max_colors)
        else:
            # Bez spaszczania - zachowaj wszystkie wykryte odcienie
            colors = colors[:max_colors] if len(colors) > max_colors else colors
        print(f" Znaleziono {len(colors)} kolor贸w ultra wysokiej jakoci (cel: {max_colors}, spaszczanie: {complexity_params.get('color_flattening', False)})")
        
        if not colors:
            print(" Nie znaleziono kolor贸w")
            return False
        
        # 7. REWOLUCYJNE tworzenie region贸w z Deep Segmentation
        regions = revolutionary_region_creation(optimized_image, colors, complexity_params)
        print(f" Utworzono {len(regions)} region贸w REWOLUCYJNEJ jakoci")
        
        if not regions:
            print("锔 Pr贸buj zaawansowan metod...")
            regions = create_color_regions_advanced(optimized_image, colors)
            print(f"猴 Zaawansowan metod utworzono {len(regions)} region贸w")
            
        if not regions:
            print("锔 Pr贸buj prost metod...")
            regions = create_color_regions_simple(optimized_image, colors)
            print(f"猴 Prost metod utworzono {len(regions)} region贸w")
            
        if not regions:
            print(" Nie mo偶na utworzy 偶adnych region贸w kolorowych")
            return False
        
        # 8. PRZEOMOWE generowanie cie偶ek SVG z Perfect Curve Technology
        svg_paths = []
        total_contours = 0
        
        for i, (color, mask) in enumerate(regions):
            print(f" REWOLUCYJNE przetwarzanie regionu {i+1}/{len(regions)} dla koloru {color}")
            
            # NOWY ALGORYTM: Revolutionary Contour Tracing
            contours = revolutionary_contour_tracing(mask, complexity_params)
            total_contours += len(contours)
            
            for j, contour in enumerate(contours):
                if len(contour) >= 3:
                    # PRZEOMOWA technologia Perfect Path Creation
                    path_data = revolutionary_path_creation(contour, complexity_params)
                    if path_data:
                        svg_paths.append((color, path_data))
        
        print(f" Wygenerowano {len(svg_paths)} cie偶ek ultra wysokiej jakoci z {total_contours} kontur贸w")
        
        if not svg_paths:
            print(" Nie wygenerowano 偶adnych cie偶ek")
            return False
        
        # Generuj ultra profesjonalne SVG
        width, height = optimized_image.size
        svg_content = generate_ultra_professional_svg(svg_paths, width, height)
        
        # Zapisz SVG
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(svg_content)
        
        print(f" Ultra wysokiej jakoci SVG zapisany do: {output_path}")
        
        # Zaawansowana walidacja jakoci
        file_size = os.path.getsize(output_path)
        quality_score = assess_svg_quality(svg_paths, file_size)
        
        print(f" Ocena jakoci: {quality_score}/100")
        print(f" Rozmiar pliku: {file_size} bajt贸w")
        print(f" Liczba kolor贸w: {len(set(color for color, _ in svg_paths))}")
        print(f" Liczba cie偶ek: {len(svg_paths)}")
        
        if file_size < 300:
            print("锔 Plik mo偶e by za may - mo偶liwe problemy z obrazem wejciowym")
            return False
        
        print(" Ultra zaawansowana wektoryzacja zakoczona sukcesem!")
        return True
        
    except Exception as e:
        print(f" Bd podczas ultra zaawansowanej wektoryzacji: {e}")
        traceback.print_exc()
        return False
    finally:
        gc.collect()

def generate_ultra_professional_svg(svg_paths, width, height):
    """Generuje REWOLUCYJNE SVG najwy偶szej jakoci na wiecie"""
    svg_content = f'''<?xml version="1.0" encoding="UTF-8"?>
<svg width="{width}" height="{height}" viewBox="0 0 {width} {height}" 
     xmlns="http://www.w3.org/2000/svg"
     xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
     xmlns:inkstitch="http://inkstitch.org/namespace"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
     xmlns:dc="http://purl.org/dc/elements/1.1/">
  <title>REVOLUTIONARY Ultra High-Quality Vector Art - AI Enhanced</title>
  <defs>
    <style>
      .revolutionary-vector-path {{
        stroke-width: 0.02;
        stroke-linejoin: round;
        stroke-linecap: round;
        fill-opacity: 1.0;
        stroke-opacity: 0.9;
        shape-rendering: geometricPrecision;
        vector-effect: non-scaling-stroke;
        paint-order: fill stroke markers;
      }}
      .high-precision-path {{
        stroke-width: 0.01;
        stroke-linejoin: miter;
        stroke-linecap: butt;
        fill-opacity: 1.0;
        stroke-opacity: 1.0;
        shape-rendering: crispEdges;
        vector-effect: non-scaling-stroke;
      }}
    </style>
  </defs>
  <g inkscape:label="Revolutionary Vector Shapes" inkscape:groupmode="layer">'''
    
    # Sortuj cie偶ki wedug jasnoci kolor贸w (ciemne na sp贸d)
    sorted_paths = sorted(svg_paths, key=lambda x: sum(x[0]))
    
    for i, (color, path_data) in enumerate(sorted_paths):
        color_hex = f"#{color[0]:02x}{color[1]:02x}{color[2]:02x}"
        color_rgb = f"rgb({color[0]},{color[1]},{color[2]})"
        
        # Ultra zaawansowane parametry haftu
        brightness = sum(color) / 3
        saturation = max(color) - min(color)
        
        # REWOLUCYJNE parametry haftu z AI-optimization
        hue = get_color_hue(color)
        saturation = max(color) - min(color)
        
        # Ultra-precyzyjne parametry bazujce na analizie kolor贸w
        if brightness < 40:  # Ultra ciemne - najwy偶sza precyzja
            row_spacing = "0.2"
            angle = str(30 + (i * 15) % 180)
            stitch_length = "2.0"
            density = "ultra-high"
            stitch_type = "satin"
        elif brightness < 80:  # Bardzo ciemne
            row_spacing = "0.25"
            angle = str(45 + (i * 20) % 180)
            stitch_length = "2.2"
            density = "very-high"
            stitch_type = "fill"
        elif brightness < 140:  # Ciemne-rednie
            row_spacing = "0.3"
            angle = str(60 + (i * 25) % 180)
            stitch_length = "2.5"
            density = "high"
            stitch_type = "fill"
        elif brightness > 220:  # Ultra jasne
            row_spacing = "0.8"
            angle = str(150 + (i * 12) % 180)
            stitch_length = "4.5"
            density = "low"
            stitch_type = "light-fill"
        elif brightness > 180:  # Bardzo jasne
            row_spacing = "0.7"
            angle = str(135 + (i * 15) % 180)
            stitch_length = "4.0"
            density = "medium-low"
            stitch_type = "light-fill"
        else:  # rednie
            row_spacing = "0.4"
            angle = str(90 + (i * 30) % 180)
            stitch_length = "3.0"
            density = "medium"
            stitch_type = "fill"
        
        # Dodatkowe parametry dla kolor贸w nasyconych
        if saturation > 150:
            row_spacing = str(float(row_spacing) * 0.8)  # Gciej dla nasyconych
            stitch_length = str(float(stitch_length) * 0.9)
        elif saturation < 30:
            row_spacing = str(float(row_spacing) * 1.2)  # Rzadziej dla szaroci
        
        # Dodatkowe parametry dla wysokiej jakoci
        underlay = "1" if brightness < 100 else "0"
        pull_compensation = "0.2" if saturation > 100 else "0.1"
        
        svg_content += f'''
    <path id="ultra-vector-path-{i}" 
          d="{path_data}" 
          class="ultra-vector-path"
          style="fill: {color_rgb}; stroke: {color_rgb}; fill-rule: evenodd;"
          inkstitch:fill="1"
          inkstitch:color="{color_hex}"
          inkstitch:angle="{angle}"
          inkstitch:row_spacing_mm="{row_spacing}"
          inkstitch:end_row_spacing_mm="{row_spacing}"
          inkstitch:max_stitch_length_mm="{stitch_length}"
          inkstitch:staggers="4"
          inkstitch:skip_last="0"
          inkstitch:underpath="{underlay}"
          inkstitch:pull_compensation_mm="{pull_compensation}"
          inkstitch:expand_mm="0.1"
          inkstitch:clockwise="true"
          data-quality="ultra-high"
          data-density="{density}" />'''
    
    svg_content += '''
  </g>
  <metadata>
    <rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
      <rdf:Description rdf:about="">
        <dc:title xmlns:dc="http://purl.org/dc/elements/1.1/">Ultra High-Quality Vector Art</dc:title>
        <dc:description xmlns:dc="http://purl.org/dc/elements/1.1/">Generated with AI-enhanced vectorization</dc:description>
        <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ultra Vector Generator</dc:creator>
      </rdf:Description>
    </rdf:RDF>
  </metadata>
</svg>'''
    
    return svg_content

def assess_svg_quality(svg_paths, file_size):
    """Ocenia jako wygenerowanego SVG"""
    try:
        score = 0
        
        # Punkty za liczb cie偶ek (max 30 punkt贸w)
        path_count = len(svg_paths)
        if path_count > 50:
            score += 30
        elif path_count > 20:
            score += 25
        elif path_count > 10:
            score += 20
        elif path_count > 5:
            score += 15
        else:
            score += 10
        
        # Punkty za r贸偶norodno kolor贸w (max 25 punkt贸w)
        unique_colors = len(set(color for color, _ in svg_paths))
        if unique_colors > 15:
            score += 25
        elif unique_colors > 10:
            score += 20
        elif unique_colors > 5:
            score += 15
        else:
            score += 10
        
        # Punkty za rozmiar pliku (max 20 punkt贸w)
        if 1000 <= file_size <= 50000:  # Optymalny zakres
            score += 20
        elif 500 <= file_size <= 100000:
            score += 15
        elif file_size > 100000:
            score += 10
        else:
            score += 5
        
        # Punkty za zo偶ono cie偶ek (max 25 punkt贸w)
        total_path_length = sum(len(path_data) for _, path_data in svg_paths)
        avg_path_complexity = total_path_length / max(path_count, 1)
        
        if avg_path_complexity > 200:
            score += 25
        elif avg_path_complexity > 100:
            score += 20
        elif avg_path_complexity > 50:
            score += 15
        else:
            score += 10
        
        return min(score, 100)
    except:
        return 50

def generate_professional_svg(svg_paths, width, height):
    """Generuje wysokiej jakoci SVG z dokadnymi cie偶kami"""
    svg_content = f'''<?xml version="1.0" encoding="UTF-8"?>
<svg width="{width}" height="{height}" viewBox="0 0 {width} {height}" 
     xmlns="http://www.w3.org/2000/svg"
     xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
     xmlns:inkstitch="http://inkstitch.org/namespace">
  <title>High-Quality Vector Pattern</title>
  <defs>
    <style>
      .vector-path {{
        stroke-width: 0.1;
        stroke-linejoin: round;
        stroke-linecap: round;
        fill-opacity: 1.0;
        stroke-opacity: 1.0;
        shape-rendering: geometricPrecision;
      }}
    </style>
  </defs>
  <g inkscape:label="Vector Shapes" inkscape:groupmode="layer">'''
    
    # Dodaj cie偶ki z wysok jakoci
    for i, (color, path_data) in enumerate(svg_paths):
        color_hex = f"#{color[0]:02x}{color[1]:02x}{color[2]:02x}"
        color_rgb = f"rgb({color[0]},{color[1]},{color[2]})"
        
        # Parametry haftu dla InkStitch
        brightness = sum(color) / 3
        if brightness < 85:
            row_spacing = "0.4"
            angle = "45"
            stitch_length = "3.0"
        elif brightness > 170:
            row_spacing = "0.6"
            angle = "135"
            stitch_length = "3.5"
        else:
            row_spacing = "0.5"
            angle = str(45 + (i * 30) % 180)
            stitch_length = "3.2"
        
        svg_content += f'''
    <path id="vector-path-{i}" 
          d="{path_data}" 
          class="vector-path"
          style="fill: {color_rgb}; stroke: none; fill-rule: evenodd;"
          inkstitch:fill="1"
          inkstitch:color="{color_hex}"
          inkstitch:angle="{angle}"
          inkstitch:row_spacing_mm="{row_spacing}"
          inkstitch:end_row_spacing_mm="{row_spacing}"
          inkstitch:max_stitch_length_mm="{stitch_length}"
          inkstitch:staggers="3"
          inkstitch:skip_last="0"
          inkstitch:underpath="0" />'''
    
    svg_content += '''
  </g>
</svg>'''
    
    return svg_content

def create_realistic_preview(svg_path, preview_path, original_image, size=(400, 400)):
    """Tworzy czysty podgld bez obram贸wek i tekstu"""
    try:
        # Utw贸rz podgld na podstawie oryginalnego obrazu
        preview_img = original_image.copy()
        preview_img.thumbnail(size, Image.Resampling.LANCZOS)
        
        # Zapisz podgld bez 偶adnych dodatkowych element贸w
        preview_img.save(preview_path, 'PNG', quality=95)
        return True
        
    except Exception as e:
        print(f"Bd podczas tworzenia podgldu: {e}")
        # Fallback - zapisz przynajmniej zmniejszony orygina
        try:
            fallback_img = original_image.copy()
            fallback_img.thumbnail(size, Image.Resampling.LANCZOS)
            fallback_img.save(preview_path, 'PNG')
            return True
        except:
            return False

@app.route('/')
def index():
    return render_template_string('''
<!DOCTYPE html>
<html>
<head>
    <title>Generator Wzor贸w Haftu - Profesjonalna Wektoryzacja</title>
    <meta charset="utf-8">
    <style>
        body { font-family: Arial, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; background: #f5f5f5; }
        .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 15px; text-align: center; margin-bottom: 30px; }
        .upload-area { border: 3px dashed #667eea; border-radius: 15px; padding: 50px; text-align: center; margin: 20px 0; background: white; transition: all 0.3s; }
        .upload-area:hover { border-color: #764ba2; transform: translateY(-2px); box-shadow: 0 5px 15px rgba(0,0,0,0.1); }
        .btn { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 15px 30px; border: none; border-radius: 8px; cursor: pointer; font-size: 16px; font-weight: bold; }
        .btn:hover { transform: translateY(-2px); box-shadow: 0 5px 15px rgba(0,0,0,0.2); }
        .result { margin-top: 30px; padding: 25px; border: 1px solid #ddd; border-radius: 15px; background: white; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .preview { max-width: 100%; height: auto; border: 2px solid #667eea; border-radius: 10px; }
        .success { color: #28a745; font-weight: bold; }
        .warning { color: #fd7e14; font-weight: bold; background: #fff3cd; padding: 15px; border-radius: 8px; margin: 20px 0; }
        .info { color: #17a2b8; background: #d1ecf1; padding: 15px; border-radius: 8px; margin: 20px 0; }
        .features { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 30px 0; }
        .feature { background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); text-align: center; }
        .feature-icon { font-size: 2em; margin-bottom: 10px; }
    </style>
</head>
<body>
    <div class="header">
        <h1>У Generator Wzor贸w Haftu</h1>
        <h2>Profesjonalna Wektoryzacja Obraz贸w</h2>
        <p>Zaawansowana technologia wektoryzacji z kompatybilnoci InkStitch</p>
    </div>
    
    <div class="features">
        <div class="feature">
            <div class="feature-icon"></div>
            <h3>Inteligentne Kolory</h3>
            <p>Zaawansowany algorytm K-means do wykrywania dominujcych kolor贸w</p>
        </div>
        <div class="feature">
            <div class="feature-icon"></div>
            <h3>Precyzyjne Kontury</h3>
            <p>Wykrywanie kontur贸w z wygadzaniem i optymalizacj cie偶ek</p>
        </div>
        <div class="feature">
            <div class="feature-icon"></div>
            <h3>Wysoka Wydajno</h3>
            <p>Zoptymalizowane algorytmy dla szybkiego przetwarzania</p>
        </div>
    </div>
    
    <div class="info">
        <strong> Nowe funkcje:</strong>
        <br> Zaawansowana wektoryzacja z krzywymi Beziera
        <br> Inteligentne wykrywanie i segmentacja kolor贸w
        <br> Kompatybilno z InkStitch i parametrami haftu
        <br> Realistyczne podgldy z efektami haftu
        <br> Adaptacyjne parametry w zale偶noci od koloru
    </div>
    
    <div class="warning">
        锔 Parametry optymalizacji:
        <br> Maksymalny rozmiar pliku: 8MB
        <br> Obrazy skalowane do 600px dla jakoci
        <br> 8 dominujcych kolor贸w maksymalnie
        <br> Wygadzone cie偶ki SVG z krzywymi
    </div>
    
    <div class="upload-area" onclick="document.getElementById('file').click()">
        <p style="font-size: 1.2em; margin-bottom: 10px;"> Kliknij tutaj lub przecignij obraz</p>
        <p>Obsugiwane formaty: PNG, JPG, JPEG, WebP, SVG</p>
        <p style="color: #666; font-size: 0.9em;">Dla najlepszych rezultat贸w u偶ywaj obraz贸w o wysokim kontracie</p>
        <input type="file" id="file" style="display: none" accept=".png,.jpg,.jpeg,.webp,.svg">
    </div>
    
    <button class="btn" onclick="uploadFile()"> Rozpocznij Profesjonaln Wektoryzacj</button>
    
    <div id="result" class="result" style="display: none;">
        <h3> Wynik wektoryzacji:</h3>
        <div id="result-content"></div>
    </div>
    
    <script>
        function uploadFile() {
            const fileInput = document.getElementById('file');
            const file = fileInput.files[0];
            
            if (!file) {
                alert('Wybierz plik do przetworzenia');
                return;
            }
            
            if (file.size > 8 * 1024 * 1024) {
                alert('Plik jest za du偶y. Maksymalny rozmiar to 8MB.');
                return;
            }
            
            const formData = new FormData();
            formData.append('file', file);
            
            document.getElementById('result').style.display = 'block';
            document.getElementById('result-content').innerHTML = 
                '<div style="text-align: center; padding: 20px;">' +
                '<div style="display: inline-block; width: 40px; height: 40px; border: 4px solid #f3f3f3; border-top: 4px solid #667eea; border-radius: 50%; animation: spin 1s linear infinite;"></div>' +
                '<p style="margin-top: 15px;"> Profesjonalna wektoryzacja w toku...</p>' +
                '<p style="color: #666;">Analizowanie kolor贸w i tworzenie cie偶ek SVG...</p>' +
                '</div>' +
                '<style>@keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }</style>';
            
            fetch('/vectorize', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    document.getElementById('result-content').innerHTML = 
                        '<div style="text-align: center;">' +
                        '<p class="success"> Profesjonalna wektoryzacja zakoczona pomylnie!</p>' +
                        '<p> Wygenerowano wysokiej jakoci plik SVG z parametrami haftu</p>' +
                        '<img src="' + data.preview_url + '" class="preview" alt="Podgld haftu" style="max-width: 400px; margin: 20px 0;">' +
                        '<br><br>' +
                        '<a href="' + data.svg_url + '" download class="btn" style="text-decoration: none; display: inline-block;"> Pobierz Profesjonalny SVG</a>' +
                        '<p style="margin-top: 15px; color: #666; font-size: 0.9em;">Plik kompatybilny z InkStitch i programami do haftu</p>' +
                        '</div>';
                } else {
                    document.getElementById('result-content').innerHTML = 
                        '<div style="text-align: center; color: #dc3545;">' +
                        '<p> Bd: ' + data.error + '</p>' +
                        '<p style="color: #666;">Spr贸buj z innym obrazem lub sprawd藕 format pliku</p>' +
                        '</div>';
                }
            })
            .catch(error => {
                document.getElementById('result-content').innerHTML = 
                    '<div style="text-align: center; color: #dc3545;">' +
                    '<p> Bd poczenia: ' + error + '</p>' +
                    '<p style="color: #666;">Sprawd藕 poczenie internetowe i spr贸buj ponownie</p>' +
                    '</div>';
            });
        }
        
        // Drag and drop functionality
        const uploadArea = document.querySelector('.upload-area');
        
        uploadArea.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadArea.style.borderColor = '#764ba2';
            uploadArea.style.backgroundColor = '#f8f9ff';
        });
        
        uploadArea.addEventListener('dragleave', (e) => {
            e.preventDefault();
            uploadArea.style.borderColor = '#667eea';
            uploadArea.style.backgroundColor = 'white';
        });
        
        uploadArea.addEventListener('drop', (e) => {
            e.preventDefault();
            uploadArea.style.borderColor = '#667eea';
            uploadArea.style.backgroundColor = 'white';
            
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                document.getElementById('file').files = files;
                uploadFile();
            }
        });
    </script>
</body>
</html>
    ''')

@app.route('/vectorize', methods=['POST'])
def vectorize():
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'Brak pliku'})
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'Nie wybrano pliku'})
        
        if not allowed_file(file.filename):
            return jsonify({'success': False, 'error': 'Nieobsugiwany format pliku'})
        
        # Sprawd藕 rozmiar pliku
        file.seek(0, os.SEEK_END)
        file_size = file.tell()
        file.seek(0)
        
        if file_size > MAX_FILE_SIZE:
            return jsonify({'success': False, 'error': f'Plik za du偶y. Maksymalny rozmiar: {MAX_FILE_SIZE/1024/1024:.1f}MB'})
        
        # Generuj unikalne ID
        timestamp = str(int(time.time() * 1000))
        
        # Zapisz plik wejciowy
        filename = secure_filename(file.filename)
        input_path = os.path.join(UPLOAD_FOLDER, 'raster', f"{timestamp}_{filename}")
        file.save(input_path)
        
        # cie偶ki plik贸w wyjciowych
        svg_filename = f"professional_{timestamp}.svg"
        svg_path = os.path.join(UPLOAD_FOLDER, 'vector_auto', svg_filename)
        preview_filename = f"{timestamp}_embroidery_preview.png"
        preview_path = os.path.join(UPLOAD_FOLDER, 'preview', preview_filename)
        
        print(f" Rozpoczynanie profesjonalnej wektoryzacji: {input_path}")
        
        # Zaaduj oryginalny obraz dla podgldu
        original_image = Image.open(input_path)
        
        # Wektoryzacja
        success = vectorize_image_improved(input_path, svg_path)
        
        if not success:
            return jsonify({'success': False, 'error': 'Nie udao si zwektoryzowa obrazu. Spr贸buj z obrazem o wy偶szym kontracie.'})
        
        # Sprawd藕 jako pliku SVG
        if not os.path.exists(svg_path):
            return jsonify({'success': False, 'error': 'Plik SVG nie zosta utworzony'})
        
        file_size = os.path.getsize(svg_path)
        if file_size < 300:
            return jsonify({'success': False, 'error': 'Wygenerowany plik SVG jest za may - mo偶liwe problemy z jakoci obrazu'})
        
        # Tworzenie realistycznego podgldu
        preview_success = create_realistic_preview(svg_path, preview_path, original_image)
        if not preview_success:
            print("锔 Nie udao si utworzy podgldu")
        
        # Wymu czyszczenie pamici
        gc.collect()
        
        print(f" Profesjonalna wektoryzacja zakoczona! Rozmiar pliku: {file_size} bajt贸w")
        
        return jsonify({
            'success': True,
            'svg_url': f'/download/vector_auto/{svg_filename}',
            'preview_url': f'/download/preview/{preview_filename}',
            'message': f'Profesjonalna wektoryzacja zakoczona! Wygenerowano plik SVG ({file_size} B) kompatybilny z InkStitch'
        })
        
    except Exception as e:
        print(f" Bd podczas wektoryzacji: {e}")
        traceback.print_exc()
        return jsonify({'success': False, 'error': 'Bd serwera podczas przetwarzania. Spr贸buj z innym obrazem.'})

@app.route('/download/<path:subpath>')
def download_file(subpath):
    try:
        file_path = os.path.join(UPLOAD_FOLDER, subpath)
        if os.path.exists(file_path):
            return send_file(file_path)
        else:
            return "Plik nie znaleziony", 404
    except Exception as e:
        return f"Bd: {e}", 500

if __name__ == '__main__':
    print("У Generator Wzor贸w Haftu - Profesjonalna Wektoryzacja")
    print(" Zaawansowane algorytmy wykrywania kolor贸w i kontur贸w")
    print(" Optymalizacja wydajnoci i jakoci")
    print(" Kompatybilno z InkStitch")
    print(" Serwer uruchamiany na porcie 5000...")
    
    app.run(host='0.0.0.0', port=5000, debug=False)